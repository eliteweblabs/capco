---
// Voice Assistant Web Interface
// Uses browser's Web Speech API for speech recognition
// Connects to AI-powered backend via API

import App from "../components/common/App.astro";
import { checkAuth } from "../lib/auth";

const { currentUser } = await checkAuth(Astro.cookies);
---

<App title="Voice Assistant" currentUser={currentUser}>
  <div class="mx-auto max-w-4xl px-4 py-8 sm:px-6 lg:px-8">
    <div class="mb-8 text-center">
      <h1 class="text-4xl font-bold text-gray-900 dark:text-white mb-2">
        ðŸŽ¤ Voice Assistant
      </h1>
      <p class="text-gray-600 dark:text-gray-400">
        Your AI-powered personal assistant powered by Claude AI and Supabase learning tables
      </p>
    </div>

    <div class="rounded-lg border border-gray-200 bg-white shadow-lg dark:border-gray-700 dark:bg-gray-800 p-8">
      <!-- Status Display -->
      <div id="status" class="mb-6 text-center">
        <div class="inline-flex items-center gap-2 px-4 py-2 rounded-full bg-gray-100 dark:bg-gray-700">
          <div id="status-indicator" class="w-3 h-3 rounded-full bg-gray-400"></div>
          <span id="status-text" class="text-sm font-medium text-gray-700 dark:text-gray-300">
            Ready - Click microphone to start
          </span>
        </div>
      </div>

      <!-- Microphone Button -->
      <div class="flex justify-center mb-8">
        <button
          id="mic-button"
          class="w-24 h-24 rounded-full bg-primary-600 hover:bg-primary-700 focus:outline-none focus:ring-4 focus:ring-primary-300 dark:focus:ring-primary-800 transition-all duration-200 flex items-center justify-center shadow-lg hover:shadow-xl"
          aria-label="Start/Stop listening"
        >
          <svg
            id="mic-icon"
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            />
          </svg>
        </button>
      </div>

      <!-- Wake Word Input -->
      <div class="mb-6">
        <label for="wake-word" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
          Wake Word (optional)
        </label>
        <input
          type="text"
          id="wake-word"
          value="hey assistant"
          class="w-full px-4 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500"
          placeholder="hey assistant"
        />
      </div>

      <!-- Conversation Display -->
      <div
        id="conversation"
        class="mb-6 max-h-96 overflow-y-auto space-y-4 p-4 bg-gray-50 dark:bg-gray-900 rounded-lg"
      >
        <div class="text-sm text-gray-500 dark:text-gray-400 text-center">
          Your conversation will appear here...
        </div>
      </div>

      <!-- Settings -->
      <div class="flex items-center justify-between text-sm mb-4">
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="enable-speech"
            checked
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Enable voice responses
        </label>
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="skip-wake-word"
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Skip wake word (process all speech)
        </label>
        <button
          id="clear-conversation"
          class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300"
        >
          Clear Conversation
        </button>
      </div>
      
      <!-- Debug Info -->
      <div id="debug-info" class="text-xs text-gray-500 dark:text-gray-400 mt-2 hidden">
        <div>Debug: <span id="debug-text">-</span></div>
      </div>
    </div>

    <!-- Instructions -->
    <div class="mt-8 rounded-lg border border-gray-200 bg-gray-50 dark:border-gray-700 dark:bg-gray-800 p-6">
      <h2 class="text-lg font-semibold text-gray-900 dark:text-white mb-3">How to Use</h2>
      <ol class="list-decimal list-inside space-y-2 text-gray-700 dark:text-gray-300">
        <li>Click the microphone button to start listening</li>
        <li>Say your wake word (e.g., "hey assistant") followed by your question</li>
        <li>The assistant will process your request using AI and respond</li>
        <li>Click the microphone again to stop listening</li>
      </ol>
      <p class="mt-4 text-sm text-gray-600 dark:text-gray-400">
        <strong>Note:</strong> This uses your browser's built-in speech recognition. Works best in Chrome, Edge, or Safari.
      </p>
    </div>
  </div>
</App>

<script>
  // Voice Assistant Web Interface
  // Uses Web Speech API for speech recognition

  const micButton = document.getElementById("mic-button");
  const micIcon = document.getElementById("mic-icon");
  const statusText = document.getElementById("status-text");
  const statusIndicator = document.getElementById("status-indicator");
  const conversation = document.getElementById("conversation");
  const wakeWordInput = document.getElementById("wake-word");
  const enableSpeechCheckbox = document.getElementById("enable-speech");
  const skipWakeWordCheckbox = document.getElementById("skip-wake-word");
  const clearButton = document.getElementById("clear-conversation");
  const debugInfo = document.getElementById("debug-info");
  const debugText = document.getElementById("debug-text");

  let recognition = null;
  let isListening = false;
  let conversationHistory = [];
  let isAwake = false;
  let wakeWord = "hey assistant";

  // Check for browser support
  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    statusText.textContent = "Speech recognition not supported in this browser";
    statusIndicator.className = "w-3 h-3 rounded-full bg-red-400";
    micButton.disabled = true;
  } else {
    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.lang = "en-US";

    recognition.onstart = () => {
      isListening = true;
      updateStatus("Listening...", "bg-blue-400");
      micButton.classList.add("ring-4", "ring-blue-300");
    };

    recognition.onend = () => {
      isListening = false;
      updateStatus("Ready - Click microphone to start", "bg-gray-400");
      micButton.classList.remove("ring-4", "ring-blue-300");
      
      // Auto-restart if it stopped unexpectedly (browser sometimes stops recognition)
      // Only restart if we were actively listening
      if (isAwake) {
        setTimeout(() => {
          if (!isListening) {
            try {
              recognition.start();
            } catch (e) {
              console.log("Recognition already starting");
            }
          }
        }, 100);
      }
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
      updateStatus(`Error: ${event.error}`, "bg-red-400");
      isListening = false;
    };

    recognition.onresult = async (event) => {
      const transcript = Array.from(event.results)
        .map((result) => result[0].transcript)
        .join(" ")
        .trim();

      if (!transcript) return;

      const skipWakeWord = skipWakeWordCheckbox.checked;
      const currentWakeWord = wakeWordInput.value.toLowerCase().trim();
      const transcriptLower = transcript.toLowerCase();

      // Check if wake word is in the transcript
      const wakeWordIndex = transcriptLower.indexOf(currentWakeWord);
      const hasWakeWord = wakeWordIndex !== -1;

      // Extract command (remove wake word if present)
      let command = transcript;
      if (hasWakeWord) {
        // Remove wake word and clean up
        command = transcript
          .replace(new RegExp(currentWakeWord, "gi"), "")
          .trim()
          .replace(/\s+/g, " ");
      }

      // Debug logging
      debugText.textContent = `Transcript: "${transcript}" | Command: "${command}" | HasWakeWord: ${hasWakeWord} | SkipWakeWord: ${skipWakeWord}`;
      debugInfo.classList.remove("hidden");

      // Process if: skip wake word mode OR wake word detected OR already awake
      const shouldProcess = skipWakeWord || hasWakeWord || isAwake;

      if (shouldProcess) {
        // Set awake state
        if (!isAwake && (skipWakeWord || hasWakeWord)) {
          isAwake = true;
          updateStatus("Awake - Processing...", "bg-green-400");
        }

        // Process command if there's content (or if skipping wake word)
        if (skipWakeWord ? transcript.length > 0 : command.length > 0) {
          const commandToProcess = skipWakeWord ? transcript : command;
          
          addMessage("user", transcript);
          updateStatus("Processing...", "bg-yellow-400");

          try {
            console.log("Processing command:", commandToProcess);
            const response = await processCommand(commandToProcess);
            console.log("Received response:", response);
            
            if (response) {
              addMessage("assistant", response);

              // Speak response if enabled
              if (enableSpeechCheckbox.checked) {
                speak(response);
              }

              updateStatus("Ready - Say wake word", "bg-gray-400");
            } else {
              throw new Error("Empty response from API");
            }

            // Return to wake word listening after a delay (unless skip mode)
            if (!skipWakeWord) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
          } catch (error) {
            console.error("Error processing command:", error);
            const errorMsg = `Sorry, I encountered an error: ${error.message || "Please try again."}`;
            addMessage("assistant", errorMsg);
            updateStatus("Error - Try again", "bg-red-400");
            if (enableSpeechCheckbox.checked) {
              speak(errorMsg);
            }
            if (!skipWakeWord) {
              isAwake = false;
            }
          }
        } else if (hasWakeWord && command.length === 0 && !skipWakeWord) {
          // Wake word detected but no command yet
          isAwake = true;
          addMessage("user", transcript);
          updateStatus("Awake - Listening for command...", "bg-green-400");
          // Keep listening - don't return
        }
      }
    };
  }

  // Process command via API
  async function processCommand(text) {
    console.log("Sending to API:", { text, historyLength: conversationHistory.length });
    
    const response = await fetch("/api/voice-assistant/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        message: text,
        conversationHistory: conversationHistory.slice(-10), // Last 10 exchanges
      }),
    });

    console.log("API response status:", response.status);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error || `API error: ${response.statusText}`);
    }

    const data = await response.json();
    console.log("API response data:", data);
    
    if (data.error) {
      throw new Error(data.error);
    }
    
    return data.response || "I'm not sure how to respond to that.";
  }

  // Add message to conversation
  function addMessage(role, text) {
    conversationHistory.push({ role, content: text });

    // Clear placeholder
    if (conversation.querySelector(".text-gray-500")) {
      conversation.innerHTML = "";
    }

    const messageDiv = document.createElement("div");
    messageDiv.className = `flex ${role === "user" ? "justify-end" : "justify-start"}`;

    const bubble = document.createElement("div");
    bubble.className = `max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
      role === "user"
        ? "bg-primary-600 text-white"
        : "bg-gray-200 dark:bg-gray-700 text-gray-900 dark:text-white"
    }`;

    bubble.textContent = text;
    messageDiv.appendChild(bubble);
    conversation.appendChild(messageDiv);
    conversation.scrollTop = conversation.scrollHeight;
  }

  // Update status
  function updateStatus(text, indicatorColor) {
    statusText.textContent = text;
    statusIndicator.className = `w-3 h-3 rounded-full ${indicatorColor}`;
  }

  // Speak text
  function speak(text) {
    if ("speechSynthesis" in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 1.0;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      window.speechSynthesis.speak(utterance);
    }
  }

  // Toggle listening
  micButton.addEventListener("click", () => {
    if (!recognition) return;

    if (isListening) {
      recognition.stop();
      isAwake = false;
    } else {
      recognition.start();
    }
  });

  // Update wake word
  wakeWordInput.addEventListener("change", (e) => {
    wakeWord = e.target.value.toLowerCase().trim();
  });

  // Clear conversation
  clearButton.addEventListener("click", () => {
    conversationHistory = [];
    conversation.innerHTML =
      '<div class="text-sm text-gray-500 dark:text-gray-400 text-center">Your conversation will appear here...</div>';
    isAwake = false;
  });
</script>

<style>
  #conversation {
    scrollbar-width: thin;
    scrollbar-color: rgba(156, 163, 175, 0.5) transparent;
  }

  #conversation::-webkit-scrollbar {
    width: 6px;
  }

  #conversation::-webkit-scrollbar-track {
    background: transparent;
  }

  #conversation::-webkit-scrollbar-thumb {
    background-color: rgba(156, 163, 175, 0.5);
    border-radius: 3px;
  }
</style>

