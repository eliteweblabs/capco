---
// Voice Assistant Web Interface
// Uses browser's Web Speech API for speech recognition
// Connects to AI-powered backend via API

import App from "../components/common/App.astro";
import { checkAuth } from "../lib/auth";

const { currentUser } = await checkAuth(Astro.cookies);
---

<App title="Voice Assistant" currentUser={currentUser}>
  <div class="mx-auto max-w-4xl px-4 py-8 sm:px-6 lg:px-8">
    <div class="mb-8 text-center">
      <h1 class="text-4xl font-bold text-gray-900 dark:text-white mb-2">
        üé§ Voice Assistant
      </h1>
      <p class="text-gray-600 dark:text-gray-400">
        Your AI-powered personal assistant powered by Claude AI and Supabase learning tables
      </p>
    </div>

    <div class="rounded-lg border border-gray-200 bg-white shadow-lg dark:border-gray-700 dark:bg-gray-800 p-8">
      <!-- Status Display -->
      <div id="status" class="mb-6 text-center">
        <div class="inline-flex items-center gap-2 px-4 py-2 rounded-full bg-gray-100 dark:bg-gray-700">
          <div id="status-indicator" class="w-3 h-3 rounded-full bg-gray-400"></div>
          <span id="status-text" class="text-sm font-medium text-gray-700 dark:text-gray-300">
            Ready - Click microphone to start
          </span>
        </div>
      </div>

      <!-- Microphone Button -->
      <div class="flex justify-center mb-8">
        <button
          id="mic-button"
          class="w-24 h-24 rounded-full bg-primary-600 hover:bg-primary-700 focus:outline-none focus:ring-4 focus:ring-primary-300 dark:focus:ring-primary-800 transition-all duration-200 flex items-center justify-center shadow-lg hover:shadow-xl"
          aria-label="Start/Stop listening"
        >
          <svg
            id="mic-icon"
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            />
          </svg>
        </button>
      </div>

      <!-- Wake Word Input -->
      <div class="mb-6">
        <label for="wake-word" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
          Wake Word
        </label>
        <input
          type="text"
          id="wake-word"
          value="Bee"
          class="w-full px-4 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500"
          placeholder="Bee"
        />
        <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
          Special commands: "Bee stop" (stop talking), "Bee remember this" (save conversation), "Bee new job" (create project)
        </p>
      </div>

      <!-- Conversation Display -->
      <div
        id="conversation"
        class="mb-6 max-h-96 overflow-y-auto space-y-4 p-4 bg-gray-50 dark:bg-gray-900 rounded-lg"
      >
        <div class="text-sm text-gray-500 dark:text-gray-400 text-center">
          Your conversation will appear here...
        </div>
      </div>

      <!-- Tags Editor (shown when ready to save) -->
      <div id="tags-editor" class="mb-6 hidden">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
          <div>
            <label class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              Tags (for saving conversation)
            </label>
            <div id="tags-container" class="flex flex-wrap gap-2 mb-2 p-3 bg-gray-50 dark:bg-gray-800 rounded-lg min-h-[3rem]">
              <!-- Tags will be dynamically added here -->
            </div>
            <div class="flex gap-2">
              <input
                type="text"
                id="tag-input"
                placeholder="Add a tag..."
                class="flex-1 px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
              />
              <button
                id="add-tag-btn"
                class="px-4 py-2 bg-primary-600 hover:bg-primary-700 text-white rounded-md text-sm font-medium transition-colors"
              >
                Add Tag
              </button>
            </div>
            <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
              Tags help organize and search saved conversations. Click √ó to remove a tag.
            </p>
          </div>
          <div>
            <label for="priority-select" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              Priority
            </label>
            <select
              id="priority-select"
              class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
            >
              <option value="0">Normal (0)</option>
              <option value="1">Low (1)</option>
              <option value="5">Medium (5)</option>
              <option value="10">High (10)</option>
              <option value="20">Critical (20)</option>
            </select>
            <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
              Higher priority entries appear first in search results.
            </p>
          </div>
        </div>
      </div>

      <!-- Quick Action Buttons -->
      <div class="mb-6">
        <p class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-3">
          Quick Actions (fallback if voice fails):
        </p>
        <div class="flex flex-wrap gap-2">
          <button
            id="btn-stop"
            class="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-offset-2"
            title="Stop speaking (Bee stop)"
          >
            üõë Stop Speaking
          </button>
          <button
            id="btn-remember"
            class="px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-purple-500 focus:ring-offset-2"
            title="Save conversation (Bee remember this)"
          >
            üíæ Remember This
          </button>
          <button
            id="btn-help"
            class="px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
            title="Show help"
          >
            ‚ùì Help
          </button>
        </div>
      </div>

      <!-- Settings -->
      <div class="flex items-center justify-between text-sm mb-4">
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="enable-speech"
            checked
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Enable voice responses
        </label>
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="skip-wake-word"
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Skip wake word (process all speech)
        </label>
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="use-cloud-transcription"
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Use cloud transcription (better accuracy)
        </label>
        <button
          id="clear-conversation"
          class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300"
        >
          Clear Conversation
        </button>
      </div>
      
      <!-- Debug Info -->
      <div id="debug-info" class="text-xs text-gray-500 dark:text-gray-400 mt-2 hidden">
        <div>Debug: <span id="debug-text">-</span></div>
      </div>
    </div>

    <!-- Instructions -->
    <div class="mt-8 rounded-lg border border-gray-200 bg-gray-50 dark:border-gray-700 dark:bg-gray-800 p-6">
      <h2 class="text-lg font-semibold text-gray-900 dark:text-white mb-3">How to Use</h2>
      <ol class="list-decimal list-inside space-y-2 text-gray-700 dark:text-gray-300">
        <li>Click the microphone button to start listening</li>
        <li>Say "Bee" followed by your question (e.g., "Bee what is fire protection?")</li>
        <li>The assistant will process your request using AI and respond</li>
        <li>Special commands:
          <ul class="list-disc list-inside ml-4 mt-1">
            <li><strong>"Bee stop"</strong> - Stop the assistant from talking</li>
            <li><strong>"Bee remember this"</strong> - Save the current conversation to memory</li>
            <li><strong>"Bee new job"</strong> or <strong>"Bee new project"</strong> - Create a new project (I'll ask you for all the details sequentially)</li>
          </ul>
        </li>
        <li>Click the microphone again to stop listening</li>
      </ol>
      <p class="mt-4 text-sm text-gray-600 dark:text-gray-400">
        <strong>Note:</strong> This uses your browser's built-in speech recognition. Works best in Chrome, Edge, or Safari.
        <br />
        <strong>Tip:</strong> Enable "Use cloud transcription" for better accuracy (requires API key configuration).
      </p>
    </div>
  </div>
</App>

<script define:vars={{ currentUserRole: currentUser?.profile?.role || "Client" }}>
  // Voice Assistant Web Interface
  // Uses Web Speech API for speech recognition

  // Get current user info from server
  const isClient = currentUserRole.toLowerCase() === "client";

  const micButton = document.getElementById("mic-button");
  const micIcon = document.getElementById("mic-icon");
  const statusText = document.getElementById("status-text");
  const statusIndicator = document.getElementById("status-indicator");
  const conversation = document.getElementById("conversation");
  const wakeWordInput = document.getElementById("wake-word");
  const enableSpeechCheckbox = document.getElementById("enable-speech");
  const skipWakeWordCheckbox = document.getElementById("skip-wake-word");
  const useCloudTranscriptionCheckbox = document.getElementById("use-cloud-transcription");
  const clearButton = document.getElementById("clear-conversation");
  const btnStop = document.getElementById("btn-stop");
  const btnRemember = document.getElementById("btn-remember");
  const btnHelp = document.getElementById("btn-help");
  const tagsEditor = document.getElementById("tags-editor");
  const tagsContainer = document.getElementById("tags-container");
  const tagInput = document.getElementById("tag-input");
  const addTagBtn = document.getElementById("add-tag-btn");
  const prioritySelect = document.getElementById("priority-select");
  
  let currentTags = []; // Store tags for current conversation
  let currentPriority = 0; // Store priority for current conversation
  const debugInfo = document.getElementById("debug-info");
  const debugText = document.getElementById("debug-text");
  
  // Project creation state
  let projectCreationState = null; // null | { step: string, data: object }
  let isAwaitingProjectField = false;

  let recognition = null;
  let isListening = false;
  let conversationHistory = [];
  let isAwake = false;
  let wakeWord = "Bee";
  let currentSpeechUtterance = null;
  let mediaRecorder = null;
  let audioChunks = [];
  let audioStream = null;

  // Check for browser support
  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    statusText.textContent = "Speech recognition not supported in this browser";
    statusIndicator.className = "w-3 h-3 rounded-full bg-red-400";
    micButton.disabled = true;
  } else {
    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true; // Enable interim results for better accuracy
    recognition.lang = "en-US";
    recognition.maxAlternatives = 3; // Get multiple transcription alternatives
    
    // Add grammar hints for better recognition (if supported)
    try {
      const grammar = `#JSGF V1.0; grammar wakeword; public <wakeword> = Bee | bee | B | b;`;
      const speechRecognitionList = new (window.SpeechGrammarList || window.webkitSpeechGrammarList)();
      speechRecognitionList.addFromString(grammar, 1);
      recognition.grammars = speechRecognitionList;
    } catch (e) {
      // Grammar not supported, continue without it
      console.log("Speech grammar not supported");
    }

    recognition.onstart = () => {
      isListening = true;
      updateStatus("Listening...", "bg-blue-400");
      micButton.classList.add("ring-4", "ring-blue-300");
    };

    recognition.onend = () => {
      isListening = false;
      updateStatus("Ready - Click microphone to start", "bg-gray-400");
      micButton.classList.remove("ring-4", "ring-blue-300");
      
      // Auto-restart if it stopped unexpectedly (browser sometimes stops recognition)
      // Only restart if we were actively listening
      if (isAwake) {
        setTimeout(() => {
          if (!isListening) {
            try {
              recognition.start();
            } catch (e) {
              console.log("Recognition already starting");
            }
          }
        }, 100);
      }
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
      updateStatus(`Error: ${event.error}`, "bg-red-400");
      isListening = false;
    };

    recognition.onresult = async (event) => {
      // If using cloud transcription, skip Web Speech API results
      if (useCloudTranscriptionCheckbox?.checked) {
        return; // Cloud transcription handles this separately
      }
      
      // Get the most confident transcript
      let transcript = "";
      let confidence = 0;
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        if (result.isFinal) {
          // Use the most confident alternative
          const alternatives = Array.from(result);
          const bestAlternative = alternatives.reduce((best, current) => {
            return (current.confidence || 0) > (best.confidence || 0) ? current : best;
          });
          
          if (bestAlternative.confidence > confidence) {
            transcript = bestAlternative.transcript;
            confidence = bestAlternative.confidence;
          }
        } else {
          // For interim results, just use the first alternative
          transcript += result[0].transcript;
        }
      }
      
      transcript = transcript.trim();
      if (!transcript) return;
      
      // Post-process transcript to fix common errors
      transcript = correctCommonErrors(transcript);
      
      // Process the transcript
      await processTranscript(transcript);
    };
    
    // Process transcript (used by both Web Speech API and cloud transcription)
    async function processTranscript(transcript) {

      const skipWakeWord = skipWakeWordCheckbox.checked;
      const currentWakeWord = wakeWordInput.value.toLowerCase().trim();
      const transcriptLower = transcript.toLowerCase();

      // Check if wake word is in the transcript
      const wakeWordIndex = transcriptLower.indexOf(currentWakeWord);
      const hasWakeWord = wakeWordIndex !== -1;

      // Extract command (remove wake word if present)
      let command = transcript;
      if (hasWakeWord) {
        // Remove wake word and clean up
        command = transcript
          .replace(new RegExp(currentWakeWord, "gi"), "")
          .trim()
          .replace(/\s+/g, " ");
      }

      // Debug logging
      debugText.textContent = `Transcript: "${transcript}" | Command: "${command}" | HasWakeWord: ${hasWakeWord} | SkipWakeWord: ${skipWakeWord}`;
      debugInfo.classList.remove("hidden");

      // Process if: skip wake word mode OR wake word detected OR already awake
      const shouldProcess = skipWakeWord || hasWakeWord || isAwake;

      if (shouldProcess) {
        // Set awake state
        if (!isAwake && (skipWakeWord || hasWakeWord)) {
          isAwake = true;
          updateStatus("Awake - Processing...", "bg-green-400");
        }

        // Process command if there's content (or if skipping wake word)
        if (skipWakeWord ? transcript.length > 0 : command.length > 0) {
          const commandToProcess = skipWakeWord ? transcript : command;
          const commandLower = commandToProcess.toLowerCase().trim();
          
          // Extract and show tags for user message
          const userTags = await extractTags(transcript);
          // Add extracted tags to current tags
          userTags.forEach(tag => addTag(tag));
          // Show tags editor
          if (tagsEditor && userTags.length > 0) {
            tagsEditor.classList.remove("hidden");
          }
          addMessage("user", transcript, userTags);
          
          // Check for special keyword commands
          if (commandLower.includes("stop") || commandLower === "stop") {
            // Stop talking command
            stopSpeaking();
            addMessage("assistant", "Stopped speaking.");
            updateStatus("Ready - Say wake word", "bg-gray-400");
            if (!skipWakeWord) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
            return;
          }
          
          if (commandLower.includes("remember this") || commandLower.includes("remember that")) {
            // Save conversation to learning table
            updateStatus("Saving conversation...", "bg-purple-400");
            try {
              const saved = await saveConversation();
              if (saved) {
                addMessage("assistant", "I've saved this conversation to my memory.");
                updateStatus("Conversation saved!", "bg-green-400");
              } else {
                addMessage("assistant", "I couldn't save the conversation. Please check the console for errors.");
                updateStatus("Save failed", "bg-red-400");
              }
            } catch (error) {
              console.error("Error saving conversation:", error);
              addMessage("assistant", "I encountered an error saving the conversation.");
              updateStatus("Error saving", "bg-red-400");
            }
            
            if (!skipWakeWord) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
            return;
          }
          
          // Handle project field collection if we're in project creation mode (check this first)
          if (isAwaitingProjectField && projectCreationState) {
            await handleProjectFieldInput(commandToProcess);
            return;
          }
          
          // Check for "Bee new job" or "Bee new project" command
          if (commandLower.includes("new job") || commandLower.includes("new project")) {
            if (isAwaitingProjectField) {
              const response = "I'm already helping you create a project. Please answer my current question, or say 'cancel' to start over.";
              addMessage("assistant", response);
              if (enableSpeechCheckbox.checked) {
                speak(response);
              }
              return;
            }
            
            // Check if user is Admin/Staff - they need to use web interface for client selection
            if (!isClient) {
              const response = "I can help you create projects, but as an Admin or Staff member, you'll need to use the web interface to select or create a client. Would you like me to open the project creation page?";
              addMessage("assistant", response);
              if (enableSpeechCheckbox.checked) {
                speak(response);
              }
              // Optionally redirect to dashboard
              // window.location.href = "/dashboard";
              return;
            }
            
            // Start project creation flow for Clients
            projectCreationState = {
              step: "address",
              data: {}
            };
            isAwaitingProjectField = true;
            const response = "I'll help you create a new project. Let's start with the project address. What's the address for this project?";
            addMessage("assistant", response);
            if (enableSpeechCheckbox.checked) {
              speak(response);
            }
            updateStatus("Creating project - Address", "bg-blue-400");
            return;
          }
          
          // Regular command processing
          updateStatus("Processing...", "bg-yellow-400");

          try {
            console.log("Processing command:", commandToProcess);
            const response = await processCommand(commandToProcess);
            console.log("Received response:", response);
            
            if (response) {
              addMessage("assistant", response);

              // Speak response if enabled
              if (enableSpeechCheckbox.checked) {
                speak(response);
              }

              updateStatus("Ready - Say wake word", "bg-gray-400");
            } else {
              throw new Error("Empty response from API");
            }

            // Return to wake word listening after a delay (unless skip mode)
            if (!skipWakeWord) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
          } catch (error) {
            console.error("Error processing command:", error);
            const errorMsg = `Sorry, I encountered an error: ${error.message || "Please try again."}`;
            addMessage("assistant", errorMsg);
            updateStatus("Error - Try again", "bg-red-400");
            if (enableSpeechCheckbox.checked) {
              speak(errorMsg);
            }
            if (!skipWakeWord) {
              isAwake = false;
            }
          }
        } else if (hasWakeWord && command.length === 0 && !skipWakeWord) {
          // Wake word detected but no command yet
          isAwake = true;
          // Extract tags even for just wake word
          const userTags = await extractTags(transcript);
          // Add extracted tags to current tags
          userTags.forEach(tag => addTag(tag));
          // Show tags editor
          if (tagsEditor && userTags.length > 0) {
            tagsEditor.classList.remove("hidden");
          }
          addMessage("user", transcript, userTags);
          updateStatus("Awake - Listening for command...", "bg-green-400");
          // Keep listening - don't return
        }
      }
    };
  }

  // Handle project field input sequentially
  async function handleProjectFieldInput(input) {
    if (!projectCreationState) return;
    
    // Check for cancellation
    const inputLower = input.toLowerCase().trim();
    if (inputLower === "cancel" || inputLower === "stop" || inputLower.includes("cancel") || inputLower.includes("never mind")) {
      projectCreationState = null;
      isAwaitingProjectField = false;
      const cancelMsg = "Project creation cancelled. You can start again anytime by saying 'Bee new job'.";
      addMessage("assistant", cancelMsg);
      if (enableSpeechCheckbox.checked) {
        speak(cancelMsg);
      }
      updateStatus("Ready - Say wake word", "bg-gray-400");
      if (!skipWakeWordCheckbox.checked) {
        setTimeout(() => {
          isAwake = false;
        }, 2000);
      }
      return;
    }
    
    const { step, data } = projectCreationState;
    let nextStep = null;
    let response = "";
    
    // Process current step and move to next
    switch (step) {
      case "address":
        data.address = input.trim();
        data.title = input.trim(); // Use address as title default
        nextStep = "title";
        response = `Got it. The address is ${data.address}. Would you like to provide a different title, or should I use the address as the title?`;
        break;
        
      case "title":
        if (input.toLowerCase().includes("use address") || input.toLowerCase().includes("same") || input.toLowerCase().includes("keep")) {
          // Keep address as title
        } else {
          data.title = input.trim();
        }
        nextStep = "architect";
        response = `Title set. Who is the architect for this project? (Say "skip" if not applicable)`;
        break;
        
      case "architect":
        if (!input.toLowerCase().includes("skip")) {
          data.architect = input.trim();
        }
        nextStep = "sqFt";
        response = `Architect noted. What's the square footage of the project? (Say "skip" if not applicable)`;
        break;
        
      case "sqFt":
        if (!input.toLowerCase().includes("skip")) {
          const sqFtMatch = input.match(/\d+/);
          if (sqFtMatch) {
            data.sqFt = sqFtMatch[0];
          }
        }
        nextStep = "units";
        response = `Square footage recorded. How many units does this project have? (Say "skip" if not applicable)`;
        break;
        
      case "units":
        if (!input.toLowerCase().includes("skip")) {
          const unitsMatch = input.match(/\d+/);
          if (unitsMatch) {
            data.units = unitsMatch[0];
          }
        }
        nextStep = "newConstruction";
        response = `Units recorded. Is this new construction? (Say "yes" or "no")`;
        break;
        
      case "newConstruction":
        data.newConstruction = input.toLowerCase().includes("yes") || input.toLowerCase().includes("y");
        nextStep = "building";
        response = `New construction: ${data.newConstruction ? "Yes" : "No"}. What type of building is this? You can choose from: Residential, Mixed use, Mercantile, Commercial, Storage, Warehouse, or Institutional. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "building":
        if (!input.toLowerCase().includes("skip")) {
          const buildingTypes = ["Residential", "Mixed use", "Mercantile", "Commercial", "Storage", "Warehouse", "Institutional"];
          const selected = buildingTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.building = selected;
          }
        }
        nextStep = "project";
        response = `Building type recorded. What type of project is this? You can choose from: Sprinkler, Alarm, Mechanical, Electrical, Plumbing, Civil engineering, or Other. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "project":
        if (!input.toLowerCase().includes("skip")) {
          const projectTypes = ["Sprinkler", "Alarm", "Mechanical", "Electrical", "Plumbing", "Civil engineering", "Other"];
          const selected = projectTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.project = selected;
          }
        }
        nextStep = "tier";
        response = `Project type recorded. What tier is this? You can choose: Tier I, Tier II, or Tier III. (Say "skip" if not applicable)`;
        break;
        
      case "tier":
        if (!input.toLowerCase().includes("skip")) {
          if (input.toLowerCase().includes("tier i") || input.toLowerCase().includes("tier 1")) {
            data.tier = ["Tier I"];
          } else if (input.toLowerCase().includes("tier ii") || input.toLowerCase().includes("tier 2")) {
            data.tier = ["Tier II"];
          } else if (input.toLowerCase().includes("tier iii") || input.toLowerCase().includes("tier 3")) {
            data.tier = ["Tier III"];
          }
        }
        nextStep = "service";
        response = `Tier recorded. What's the supply or service type? Options are: Pump & Tank 300, Pump & Tank 600, 2' Copper, 4' Ductile, 6' Ductile, or Unknown. (Say "skip" if not applicable)`;
        break;
        
      case "service":
        if (!input.toLowerCase().includes("skip")) {
          const serviceTypes = ["Pump & Tank 300", "Pump & Tank 600", "Pump & Tank", "2' Copper", "4' Ductile", "6' Ductile", "Unknown"];
          const selected = serviceTypes.find(type => 
            input.toLowerCase().includes(type.toLowerCase().replace("'", ""))
          );
          if (selected) {
            data.service = selected === "Pump & Tank" ? "Pump & Tank 300" : selected;
          }
        }
        nextStep = "nfpaVersion";
        response = `Service type recorded. What NFPA version applies? Options are: 13, 13R, or 13D. (Say "skip" if not applicable)`;
        break;
        
      case "nfpaVersion":
        if (!input.toLowerCase().includes("skip")) {
          if (input.toLowerCase().includes("13r")) {
            data.nfpaVersion = "13R";
          } else if (input.toLowerCase().includes("13d")) {
            data.nfpaVersion = "13D";
          } else if (input.match(/\b13\b/)) {
            data.nfpaVersion = "13";
          }
        }
        nextStep = "requestedDocs";
        response = `NFPA version recorded. What reports are required? Options include: Narrative, Sprinkler, Alarm, Hydraulic Calculations, Fire Hydrant Flow Test, NFPA 241, IEBC, or IBC. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "requestedDocs":
        if (!input.toLowerCase().includes("skip")) {
          const docTypes = ["Narrative", "Sprinkler", "Alarm", "Hydraulic Calculations", "Fire Hydrant Flow Test", "NFPA 241", "IEBC", "IBC"];
          const selected = docTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.requestedDocs = selected;
          } else {
            // Default to common ones
            data.requestedDocs = ["Narrative", "Sprinkler", "Hydraulic Calculations", "Fire Hydrant Flow Test"];
          }
        } else {
          // Default to common ones
          data.requestedDocs = ["Narrative", "Sprinkler", "Hydraulic Calculations", "Fire Hydrant Flow Test"];
        }
        nextStep = "description";
        response = `Reports required recorded. Would you like to add a description for this project? (Say "skip" if not needed)`;
        break;
        
      case "description":
        if (!input.toLowerCase().includes("skip")) {
          data.description = input.trim();
        }
        nextStep = "siteAccess";
        response = `Description added. What's the site access information? (Say "skip" if not applicable)`;
        break;
        
      case "siteAccess":
        if (!input.toLowerCase().includes("skip")) {
          data.siteAccess = input.trim();
        }
        nextStep = "commencementOfConstruction";
        response = `Site access recorded. What's the estimated commencement of construction? (Say "skip" if not applicable)`;
        break;
        
      case "commencementOfConstruction":
        if (!input.toLowerCase().includes("skip")) {
          data.commencementOfConstruction = input.trim();
        }
        nextStep = "buildingHeight";
        response = `Commencement date recorded. What's the building height? (Say "skip" if not applicable)`;
        break;
        
      case "buildingHeight":
        if (!input.toLowerCase().includes("skip")) {
          const heightMatch = input.match(/\d+/);
          if (heightMatch) {
            data.buildingHeight = heightMatch[0];
          }
        }
        nextStep = "floorsBelowGrade";
        response = `Building height recorded. How many floors below grade? (Say "skip" if not applicable)`;
        break;
        
      case "floorsBelowGrade":
        if (!input.toLowerCase().includes("skip")) {
          const floorsMatch = input.match(/\d+/);
          if (floorsMatch) {
            data.floorsBelowGrade = floorsMatch[0];
          }
        }
        nextStep = "complete";
        response = `All information collected. Creating your project now...`;
        break;
        
      case "complete":
        // Shouldn't reach here, but handle it
        return;
    }
    
    // Add assistant response
    addMessage("assistant", response);
    if (enableSpeechCheckbox.checked) {
      speak(response);
    }
    
    // Update state
    if (nextStep === "complete") {
      projectCreationState.step = "complete";
      // Create the project
      await createProjectFromVoice(data);
    } else {
      projectCreationState.step = nextStep;
      updateStatus(`Creating project - ${nextStep}`, "bg-blue-400");
    }
  }
  
  // Create project from collected voice data
  async function createProjectFromVoice(projectData) {
    updateStatus("Creating project...", "bg-purple-400");
    
    try {
      // Ensure arrays are arrays
      if (projectData.building && !Array.isArray(projectData.building)) {
        projectData.building = [projectData.building];
      }
      if (projectData.project && !Array.isArray(projectData.project)) {
        projectData.project = [projectData.project];
      }
      if (projectData.tier && !Array.isArray(projectData.tier)) {
        projectData.tier = [projectData.tier];
      }
      if (projectData.requestedDocs && !Array.isArray(projectData.requestedDocs)) {
        projectData.requestedDocs = [projectData.requestedDocs];
      }
      
      // Convert numeric strings to numbers
      if (projectData.sqFt) projectData.sqFt = parseInt(projectData.sqFt);
      if (projectData.units) projectData.units = parseInt(projectData.units);
      if (projectData.buildingHeight) projectData.buildingHeight = parseInt(projectData.buildingHeight);
      if (projectData.floorsBelowGrade) projectData.floorsBelowGrade = parseInt(projectData.floorsBelowGrade);
      
      const response = await fetch("/api/projects/upsert", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(projectData),
      });
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.error || `Failed to create project: ${response.statusText}`);
      }
      
      const result = await response.json();
      
      if (result.success) {
        const successMsg = `Great! I've successfully created your project "${result.project.title || result.project.address}". The project ID is ${result.project.id}.`;
        addMessage("assistant", successMsg);
        if (enableSpeechCheckbox.checked) {
          speak(successMsg);
        }
        updateStatus("Project created!", "bg-green-400");
        
        // Reset project creation state
        projectCreationState = null;
        isAwaitingProjectField = false;
        
        if (!skipWakeWordCheckbox.checked) {
          setTimeout(() => {
            isAwake = false;
          }, 3000);
        }
      } else {
        throw new Error(result.error || "Failed to create project");
      }
    } catch (error) {
      console.error("Error creating project:", error);
      const errorMsg = `Sorry, I encountered an error creating the project: ${error.message || "Please try again."}`;
      addMessage("assistant", errorMsg);
      updateStatus("Error creating project", "bg-red-400");
      if (enableSpeechCheckbox.checked) {
        speak(errorMsg);
      }
      
      // Reset project creation state on error
      projectCreationState = null;
      isAwaitingProjectField = false;
      
      if (!skipWakeWordCheckbox.checked) {
        setTimeout(() => {
          isAwake = false;
        }, 3000);
      }
    }
  }

  // Process command via API
  async function processCommand(text) {
    console.log("Sending to API:", { text, historyLength: conversationHistory.length });
    
    const response = await fetch("/api/voice-assistant/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        message: text,
        conversationHistory: conversationHistory.slice(-10), // Last 10 exchanges
      }),
    });

    console.log("API response status:", response.status);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error || `API error: ${response.statusText}`);
    }

    const data = await response.json();
    console.log("API response data:", data);
    
    if (data.error) {
      throw new Error(data.error);
    }
    
    return data.response || "I'm not sure how to respond to that.";
  }

  // Add tag to current tags and update UI
  function addTag(tag) {
    const normalizedTag = tag.toLowerCase().trim();
    if (normalizedTag && !currentTags.includes(normalizedTag)) {
      currentTags.push(normalizedTag);
      updateTagsDisplay();
    }
  }

  // Remove tag from current tags
  function removeTag(tag) {
    currentTags = currentTags.filter(t => t !== tag);
    updateTagsDisplay();
  }

  // Update tags display in editor
  function updateTagsDisplay() {
    tagsContainer.innerHTML = "";
    
    if (currentTags.length === 0) {
      const emptyMsg = document.createElement("div");
      emptyMsg.className = "text-sm text-gray-400 italic";
      emptyMsg.textContent = "No tags yet. Add tags above or they'll be auto-extracted.";
      tagsContainer.appendChild(emptyMsg);
      return;
    }

    currentTags.forEach(tag => {
      const tagDiv = document.createElement("div");
      tagDiv.className = "inline-flex items-center gap-1 px-2 py-1 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 rounded text-sm";
      
      const tagSpan = document.createElement("span");
      tagSpan.textContent = `#${tag}`;
      
      const removeBtn = document.createElement("button");
      removeBtn.className = "ml-1 text-blue-600 dark:text-blue-300 hover:text-blue-800 dark:hover:text-blue-100 font-bold";
      removeBtn.textContent = "√ó";
      removeBtn.title = "Remove tag";
      removeBtn.onclick = () => removeTag(tag);
      
      tagDiv.appendChild(tagSpan);
      tagDiv.appendChild(removeBtn);
      tagsContainer.appendChild(tagDiv);
    });
  }

  // Add message to conversation
  function addMessage(role, text, tags = []) {
    conversationHistory.push({ role, content: text });

    // Add tags to current tags if provided
    if (tags && tags.length > 0) {
      tags.forEach(tag => addTag(tag));
      // Show tags editor if tags are present
      if (tagsEditor) {
        tagsEditor.classList.remove("hidden");
      }
    }

    // Clear placeholder
    if (conversation.querySelector(".text-gray-500")) {
      conversation.innerHTML = "";
    }

    const messageDiv = document.createElement("div");
    messageDiv.className = `flex ${role === "user" ? "justify-end" : "justify-start"} mb-2`;

    const bubble = document.createElement("div");
    bubble.className = `max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
      role === "user"
        ? "bg-primary-600 text-white"
        : role === "system"
        ? "bg-yellow-100 dark:bg-yellow-900 text-yellow-800 dark:text-yellow-200 border border-yellow-300 dark:border-yellow-700"
        : "bg-gray-200 dark:bg-gray-700 text-gray-900 dark:text-white"
    }`;

    bubble.textContent = text;
    
    // Add tags display if present (read-only in conversation)
    if (tags && tags.length > 0) {
      const tagsDiv = document.createElement("div");
      tagsDiv.className = "mt-2 flex flex-wrap gap-1";
      tags.forEach(tag => {
        const tagSpan = document.createElement("span");
        tagSpan.className = "text-xs px-2 py-1 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 rounded";
        tagSpan.textContent = `#${tag}`;
        tagsDiv.appendChild(tagSpan);
      });
      bubble.appendChild(tagsDiv);
    }
    
    messageDiv.appendChild(bubble);
    conversation.appendChild(messageDiv);
    conversation.scrollTop = conversation.scrollHeight;
  }
  
  // Extract and display tags for user messages
  async function processMessageWithTags(role, text) {
    if (role === "user") {
      // Extract tags from user message
      const tags = await extractTags(text);
      if (tags.length > 0) {
        addMessage(role, text, tags);
        // Show tags in debug
        debugText.textContent += ` | Tags: ${tags.join(", ")}`;
      } else {
        addMessage(role, text);
      }
    } else {
      addMessage(role, text);
    }
  }

  // Update status
  function updateStatus(text, indicatorColor) {
    statusText.textContent = text;
    statusIndicator.className = `w-3 h-3 rounded-full ${indicatorColor}`;
  }

  // Speak text
  function speak(text) {
    if ("speechSynthesis" in window) {
      // Stop any current speech
      stopSpeaking();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 1.0;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      currentSpeechUtterance = utterance;
      window.speechSynthesis.speak(utterance);
    }
  }

  // Stop speaking
  function stopSpeaking() {
    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel();
      currentSpeechUtterance = null;
    }
  }

  // Extract tags from text using AI
  async function extractTags(text) {
    try {
      const response = await fetch("/api/voice-assistant/extract-tags", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ text }),
      });

      if (!response.ok) {
        console.error("Tag extraction failed");
        return [];
      }

      const data = await response.json();
      return data.tags || [];
    } catch (error) {
      console.error("Error extracting tags:", error);
      return [];
    }
  }

  // Save conversation to learning table
  async function saveConversation() {
    if (conversationHistory.length === 0) {
      console.log("No conversation to save");
      return false;
    }

    // Get the last exchange (user question + assistant response)
    const lastExchange = conversationHistory.slice(-2);
    if (lastExchange.length < 2) {
      console.log("Not enough conversation to save");
      return false;
    }

    const userMessage = lastExchange.find(m => m.role === "user")?.content || "";
    const assistantMessage = lastExchange.find(m => m.role === "assistant")?.content || "";

    if (!userMessage || !assistantMessage) {
      console.log("Missing user or assistant message");
      return false;
    }

    // Create a knowledge entry from the conversation
    const title = userMessage.substring(0, 100) + (userMessage.length > 100 ? "..." : "");
    const content = `User asked: "${userMessage}"\n\nAssistant responded: "${assistantMessage}"`;

    // Use current tags (from manual entry + auto-extraction), or extract if none
    let tagsToSave = [...currentTags];
    
    if (tagsToSave.length === 0) {
      // Auto-extract tags if none manually added
      const combinedText = `${userMessage} ${assistantMessage}`;
      const extractedTags = await extractTags(combinedText);
      tagsToSave = extractedTags;
      // Add extracted tags to current tags for display
      extractedTags.forEach(tag => addTag(tag));
    }
    
    // Get priority from dropdown
    const priority = parseInt(prioritySelect?.value || "0", 10);
    currentPriority = priority;
    
    console.log("Saving with tags:", tagsToSave, "and priority:", priority);

    try {
      const response = await fetch("/api/voice-assistant/remember", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          title,
          content,
          category: "conversation_memory",
          tags: tagsToSave, // Use current tags (manual + auto-extracted)
          priority: priority, // Include priority
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.error || `API error: ${response.statusText}`);
      }

      const data = await response.json();
      console.log("Conversation saved with tags and priority:", data);
      
      // Show confirmation with tags and priority
      const priorityLabels = { 0: "Normal", 1: "Low", 5: "Medium", 10: "High", 20: "Critical" };
      const priorityLabel = priorityLabels[priority] || `Priority ${priority}`;
      
      if (tagsToSave.length > 0) {
        const tagsDisplay = tagsToSave.map(tag => `#${tag}`).join(" ");
        addMessage("system", `Conversation saved with tags: ${tagsDisplay} (Priority: ${priorityLabel})`);
      } else {
        addMessage("system", `Conversation saved (Priority: ${priorityLabel})`);
      }
      
      // Clear tags and reset priority after saving
      currentTags = [];
      currentPriority = 0;
      updateTagsDisplay();
      if (prioritySelect) {
        prioritySelect.value = "0";
      }
      
      return true;
    } catch (error) {
      console.error("Error saving conversation:", error);
      return false;
    }
  }

  // Start audio recording for cloud transcription
  async function startAudioRecording() {
    try {
      audioStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        } 
      });
      
      mediaRecorder = new MediaRecorder(audioStream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      audioChunks = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };
      
      // Handle when recording stops (for cloud transcription)
      mediaRecorder.onstop = async () => {
        if (audioChunks.length > 0) {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          audioChunks = [];
          
          // Stop all tracks
          if (audioStream) {
            audioStream.getTracks().forEach(track => track.stop());
            audioStream = null;
          }
          
          // Transcribe with cloud API
          updateStatus("Transcribing...", "bg-purple-400");
          const cloudTranscript = await transcribeWithCloud(audioBlob);
          
          if (cloudTranscript && cloudTranscript.length > 0) {
            const correctedTranscript = correctCommonErrors(cloudTranscript);
            await processTranscript(correctedTranscript);
          }
          
          // Restart recording for next command if still listening
          if (isListening && useCloudTranscriptionCheckbox?.checked) {
            await startAudioRecording();
          }
        }
      };
      
      mediaRecorder.start(100); // Collect data every 100ms
    } catch (error) {
      console.error("Error starting audio recording:", error);
    }
  }

  // Stop audio recording (triggers onstop handler)
  function stopAudioRecording() {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
  }

  // Transcribe using cloud API
  async function transcribeWithCloud(audioBlob) {
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      
      const response = await fetch('/api/voice-assistant/transcribe', {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error('Cloud transcription failed');
      }
      
      const data = await response.json();
      return data.transcript || '';
    } catch (error) {
      console.error('Cloud transcription error:', error);
      return null;
    }
  }

  // Toggle listening
  micButton.addEventListener("click", async () => {
    if (!recognition) return;

    if (isListening) {
      recognition.stop();
      isAwake = false;
      
      // Stop audio recording if using cloud transcription
      if (useCloudTranscriptionCheckbox?.checked && mediaRecorder) {
        stopAudioRecording();
      }
    } else {
      // Start audio recording if cloud transcription is enabled
      if (useCloudTranscriptionCheckbox?.checked) {
        await startAudioRecording();
      }
      
      recognition.start();
    }
  });
  
  // Handle manual stop for cloud transcription (when user pauses)
  let silenceTimer = null;
  function resetSilenceTimer() {
    if (silenceTimer) clearTimeout(silenceTimer);
    
    if (useCloudTranscriptionCheckbox?.checked && mediaRecorder && mediaRecorder.state === 'recording') {
      // Stop recording after 2 seconds of silence (user finished speaking)
      silenceTimer = setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          stopAudioRecording();
        }
      }, 2000);
    }
  }
  
  // Reset silence timer on any speech activity
  if (recognition) {
    const originalOnResult = recognition.onresult;
    recognition.onresult = (event) => {
      resetSilenceTimer();
      if (originalOnResult) originalOnResult.call(recognition, event);
    };
  }

  // Post-process transcript to fix common errors
  function correctCommonErrors(text) {
    let corrected = text;
    
    // Common transcription errors and corrections
    const corrections = {
      // Wake word variations
      "be": "Bee",
      "b": "Bee",
      "bee": "Bee",
      
      // Common word errors
      "what's": "what is",
      "whats": "what is",
      "that's": "that is",
      "thats": "that is",
      "it's": "it is",
      "its": "it is",
      "you're": "you are",
      "youre": "you are",
      "I'm": "I am",
      "im": "I am",
      
      // Technical terms that are often misheard
      "nfpa": "NFPA",
      "n f p a": "NFPA",
      "n f p": "NFPA",
      "fire protection": "fire protection",
      "fire alarm": "fire alarm",
      "fire sprinkler": "fire sprinkler",
      
      // Number corrections
      "one": "1",
      "two": "2",
      "three": "3",
      "four": "4",
      "five": "5",
      
      // Common phrase corrections
      "remember this": "remember this",
      "remember that": "remember this",
      "stop talking": "stop",
      "stop speaking": "stop",
    };
    
    // Apply corrections (case-insensitive)
    Object.keys(corrections).forEach((error) => {
      const regex = new RegExp(`\\b${error}\\b`, "gi");
      corrected = corrected.replace(regex, corrections[error]);
    });
    
    // Fix double spaces
    corrected = corrected.replace(/\s+/g, " ");
    
    return corrected.trim();
  }

  // Update wake word
  wakeWordInput.addEventListener("change", (e) => {
    wakeWord = e.target.value.toLowerCase().trim();
  });

  // Stop button handler
  btnStop.addEventListener("click", () => {
    stopSpeaking();
    addMessage("assistant", "Stopped speaking.");
    updateStatus("Ready - Say wake word", "bg-gray-400");
    isAwake = false;
  });

  // Remember button handler
  btnRemember.addEventListener("click", async () => {
    updateStatus("Saving conversation...", "bg-purple-400");
    try {
      const saved = await saveConversation();
      if (saved) {
        addMessage("assistant", "I've saved this conversation to my memory.");
        updateStatus("Conversation saved!", "bg-green-400");
      } else {
        addMessage("assistant", "I couldn't save the conversation. Please check the console for errors.");
        updateStatus("Save failed", "bg-red-400");
      }
    } catch (error) {
      console.error("Error saving conversation:", error);
      addMessage("assistant", "I encountered an error saving the conversation.");
      updateStatus("Error saving", "bg-red-400");
    }
  });

  // Help button handler
  btnHelp.addEventListener("click", () => {
    const helpText = `Here's what I can do:

üé§ Voice Commands:
‚Ä¢ "Bee [your question]" - Ask me anything
‚Ä¢ "Bee stop" - Stop me from talking
‚Ä¢ "Bee remember this" - Save our conversation
‚Ä¢ "Bee new job" or "Bee new project" - Create a new project (I'll ask you for all the details)

üí° Tips:
‚Ä¢ Speak clearly for best results
‚Ä¢ Enable cloud transcription for better accuracy
‚Ä¢ Use the buttons below if voice recognition fails

üîß Available Actions:
‚Ä¢ Stop Speaking - Interrupts my speech
‚Ä¢ Remember This - Saves conversation to memory
‚Ä¢ Help - Shows this message`;

    addMessage("assistant", helpText);
    if (enableSpeechCheckbox.checked) {
      speak("Here's what I can do. Use Bee followed by your question, or say Bee stop to stop me from talking, or Bee remember this to save our conversation, or Bee new job to create a new project.");
    }
  });

  // Add tag button handler
  addTagBtn.addEventListener("click", () => {
    const tagValue = tagInput.value.trim();
    if (tagValue) {
      addTag(tagValue);
      tagInput.value = "";
      // Show tags editor if hidden
      if (tagsEditor) {
        tagsEditor.classList.remove("hidden");
      }
    }
  });

  // Add tag on Enter key
  tagInput.addEventListener("keypress", (e) => {
    if (e.key === "Enter") {
      e.preventDefault();
      addTagBtn.click();
    }
  });

  // Clear conversation
  clearButton.addEventListener("click", () => {
    conversationHistory = [];
    currentTags = [];
    currentPriority = 0;
    projectCreationState = null;
    isAwaitingProjectField = false;
    conversation.innerHTML =
      '<div class="text-sm text-gray-500 dark:text-gray-400 text-center">Your conversation will appear here...</div>';
    updateTagsDisplay();
    if (prioritySelect) {
      prioritySelect.value = "0";
    }
    if (tagsEditor) {
      tagsEditor.classList.add("hidden");
    }
    isAwake = false;
    updateStatus("Ready - Click microphone to start", "bg-gray-400");
  });
</script>

<style>
  #conversation {
    scrollbar-width: thin;
    scrollbar-color: rgba(156, 163, 175, 0.5) transparent;
  }

  #conversation::-webkit-scrollbar {
    width: 6px;
  }

  #conversation::-webkit-scrollbar-track {
    background: transparent;
  }

  #conversation::-webkit-scrollbar-thumb {
    background-color: rgba(156, 163, 175, 0.5);
    border-radius: 3px;
  }
</style>

