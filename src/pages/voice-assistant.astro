---
// Voice Assistant Web Interface
// Uses browser's Web Speech API for speech recognition
// Connects to AI-powered backend via API

import App from "../components/common/App.astro";
import { checkAuth } from "../lib/auth";

const { currentUser } = await checkAuth(Astro.cookies);
---

<App title="Voice Assistant" currentUser={currentUser}>
  <!-- Mobile-optimized container with full-screen support -->
  <div id="voice-assistant-container" class="mx-auto max-w-4xl px-4 py-4 sm:px-6 sm:py-8 lg:px-8 min-h-screen sm:min-h-0">
    <div class="mb-8 text-center">
      <h1 class="text-4xl font-bold text-gray-900 dark:text-white mb-2">
        üé§ Voice Assistant
      </h1>
      <p class="text-gray-600 dark:text-gray-400">
        Your AI-powered personal assistant powered by Claude AI and Supabase learning tables
      </p>
    </div>

    <div class="rounded-lg border border-gray-200 bg-white shadow-lg dark:border-gray-700 dark:bg-gray-800 p-8">
      <!-- Status Display -->
      <div id="status" class="mb-6 text-center">
        <div class="inline-flex items-center gap-2 px-4 py-2 rounded-full bg-gray-100 dark:bg-gray-700">
          <div id="status-indicator" class="w-3 h-3 rounded-full bg-gray-400"></div>
          <span id="status-text" class="text-sm font-medium text-gray-700 dark:text-gray-300">
            Ready - Click microphone to start
          </span>
        </div>
      </div>

      <!-- Microphone Button with enhanced mobile support -->
      <div class="flex justify-center mb-8">
        <button
          id="mic-button"
          class="w-24 h-24 sm:w-28 sm:h-28 rounded-full bg-primary-600 hover:bg-primary-700 active:bg-primary-800 focus:outline-none focus:ring-4 focus:ring-primary-300 dark:focus:ring-primary-800 transition-all duration-200 flex items-center justify-center shadow-lg hover:shadow-xl active:scale-95 touch-manipulation"
          aria-label="Start/Stop listening"
          style="touch-action: manipulation; -webkit-tap-highlight-color: transparent;"
        >
          <svg
            id="mic-icon"
            class="w-12 h-12 text-white"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
            />
          </svg>
        </button>
      </div>

      <!-- Wake Word Input -->
      <div class="mb-6">
        <label for="wake-word" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
          Wake Word
        </label>
        <input
          type="text"
          id="wake-word"
          value="Bee"
          class="w-full px-4 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500"
          placeholder="Bee"
        />
        <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
          Special commands: "Bee stop" (stop talking), "Bee remember this" (save conversation), "Bee new job" (create project)
        </p>
      </div>

      <!-- Conversation Display -->
      <div
        id="conversation"
        class="mb-6 max-h-96 overflow-y-auto space-y-4 p-4 bg-gray-50 dark:bg-gray-900 rounded-lg"
      >
        <div class="text-sm text-gray-500 dark:text-gray-400 text-center">
          Your conversation will appear here...
        </div>
      </div>

      <!-- Tags Editor (shown when ready to save) -->
      <div id="tags-editor" class="mb-6 hidden">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
          <div>
            <label class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              Tags (for saving conversation)
            </label>
            <div id="tags-container" class="flex flex-wrap gap-2 mb-2 p-3 bg-gray-50 dark:bg-gray-800 rounded-lg min-h-[3rem]">
              <!-- Tags will be dynamically added here -->
            </div>
            <div class="flex gap-2">
              <input
                type="text"
                id="tag-input"
                placeholder="Add a tag..."
                class="flex-1 px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
              />
              <button
                id="add-tag-btn"
                class="px-4 py-2 bg-primary-600 hover:bg-primary-700 text-white rounded-md text-sm font-medium transition-colors"
              >
                Add Tag
              </button>
            </div>
            <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
              Tags help organize and search saved conversations. Click √ó to remove a tag.
            </p>
          </div>
          <div>
            <label for="priority-select" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              Priority
            </label>
            <select
              id="priority-select"
              class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
            >
              <option value="0">Normal (0)</option>
              <option value="1">Low (1)</option>
              <option value="5">Medium (5)</option>
              <option value="10">High (10)</option>
              <option value="20">Critical (20)</option>
            </select>
            <p class="mt-2 text-xs text-gray-500 dark:text-gray-400">
              Higher priority entries appear first in search results.
            </p>
          </div>
        </div>
      </div>

      <!-- File Upload Section -->
      <div class="mb-6 p-4 bg-gray-50 dark:bg-gray-900 rounded-lg border border-gray-200 dark:border-gray-700">
        <h3 class="text-sm font-semibold text-gray-700 dark:text-gray-300 mb-3">Upload Documents or Images</h3>
        <div class="flex items-center gap-4 flex-wrap">
          <label
            for="file-input"
            class="flex items-center gap-2 px-4 py-2 bg-white dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded-lg cursor-pointer hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors"
          >
            <svg class="h-5 w-5 text-gray-600 dark:text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"></path>
            </svg>
            <span class="text-sm text-gray-700 dark:text-gray-300">Choose File</span>
          </label>
          <input
            type="file"
            id="file-input"
            accept=".pdf,.png,.jpg,.jpeg,.gif,.webp"
            class="hidden"
          />
          <span id="file-name" class="text-sm text-gray-500 dark:text-gray-400 flex-1 min-w-[150px]">
            No file selected
          </span>
          <button
            id="upload-btn"
            class="px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 transition-colors disabled:opacity-50 disabled:cursor-not-allowed text-sm font-medium"
            disabled
          >
            Process File
          </button>
        </div>
        <div id="file-preview" class="mt-4 hidden"></div>
        <div id="file-status" class="mt-2 text-sm"></div>
      </div>

      <!-- Quick Action Buttons -->
      <div class="mb-6">
        <p class="text-sm font-medium text-gray-700 dark:text-gray-300 mb-3">
          Quick Actions (fallback if voice fails):
        </p>
        <div class="flex flex-wrap gap-2">
          <button
            id="btn-stop"
            class="px-4 py-2 bg-red-600 hover:bg-red-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-offset-2"
            title="Stop speaking (Bee stop)"
          >
            üõë Stop Speaking
          </button>
          <button
            id="btn-remember"
            class="px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-purple-500 focus:ring-offset-2"
            title="Save conversation (Bee remember this)"
          >
            üíæ Remember This
          </button>
          <button
            id="btn-help"
            class="px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2"
            title="Show help"
          >
            ‚ùì Help
          </button>
          <button
            id="btn-export-logs"
            class="px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-green-500 focus:ring-offset-2"
            title="Export logs"
          >
            üìã Export Logs (<span id="log-count">0</span>)
          </button>
        </div>
      </div>

      <!-- Settings -->
      <div class="flex items-center justify-between text-sm mb-4">
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="enable-speech"
            checked
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Enable voice responses
        </label>
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="skip-wake-word"
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Skip wake word (process all speech)
        </label>
        <label class="flex items-center gap-2 text-gray-700 dark:text-gray-300">
          <input
            type="checkbox"
            id="enable-tags"
            class="rounded border-gray-300 text-primary-600 focus:ring-primary-500"
          />
          Enable tag extraction (may affect agent)
        </label>
        <button
          id="clear-conversation"
          class="text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300"
        >
          Clear Conversation
        </button>
      </div>
      
      <!-- Debug Info -->
      <div id="debug-info" class="text-xs text-gray-500 dark:text-gray-400 mt-2 hidden">
        <div>Debug: <span id="debug-text">-</span></div>
      </div>
    </div>

    <!-- Patterns Management Section -->
    <div class="mt-8 rounded-lg border border-gray-200 bg-white shadow-lg dark:border-gray-700 dark:bg-gray-800 p-6">
      <div class="flex items-center justify-between mb-4">
        <h2 class="text-xl font-semibold text-gray-900 dark:text-white">Patterns & Memory</h2>
        <button
          id="toggle-patterns"
          class="px-4 py-2 text-sm font-medium text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300"
        >
          <span id="patterns-toggle-text">Show</span> Patterns
        </button>
      </div>

      <div id="patterns-section" class="hidden">
        <!-- Add Pattern Form -->
        <div class="mb-6 rounded-lg border border-gray-200 bg-gray-50 dark:border-gray-600 dark:bg-gray-900 p-4">
          <h3 class="text-lg font-medium text-gray-900 dark:text-white mb-3">Add New Pattern</h3>
          <form id="pattern-form" class="space-y-3">
            <div>
              <label for="pattern-title" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                Pattern Title <span class="text-red-500">*</span>
              </label>
              <input
                type="text"
                id="pattern-title"
                required
                class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
                placeholder="e.g., Project Creation Pattern, Client Greeting"
              />
            </div>
            <div>
              <label for="pattern-content" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                Pattern Content <span class="text-red-500">*</span>
              </label>
              <textarea
                id="pattern-content"
                required
                rows="3"
                class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
                placeholder="Describe the pattern or behavior the assistant should remember..."
              ></textarea>
            </div>
            <div class="grid grid-cols-2 gap-3">
              <div>
                <label for="pattern-category" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                  Category
                </label>
                <input
                  type="text"
                  id="pattern-category"
                  value="pattern"
                  class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
                  placeholder="pattern"
                />
              </div>
              <div>
                <label for="pattern-priority" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                  Priority
                </label>
                <input
                  type="number"
                  id="pattern-priority"
                  value="0"
                  min="-10"
                  max="10"
                  class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
                />
              </div>
            </div>
            <div>
              <label for="pattern-tags" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-1">
                Tags (comma-separated)
              </label>
              <input
                type="text"
                id="pattern-tags"
                class="w-full px-3 py-2 border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500 text-sm"
                placeholder="e.g., greeting, project, workflow"
              />
            </div>
            <button
              type="submit"
              class="w-full px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 focus:outline-none focus:ring-2 focus:ring-primary-500 focus:ring-offset-2 transition-colors"
            >
              Save Pattern
            </button>
          </form>
        </div>

        <!-- Patterns List -->
        <div>
          <div class="flex items-center justify-between mb-3">
            <h3 class="text-lg font-medium text-gray-900 dark:text-white">Saved Patterns</h3>
            <div class="flex gap-2">
              <input
                type="text"
                id="pattern-search"
                placeholder="Search patterns..."
                class="px-3 py-1 text-sm border border-gray-300 rounded-md dark:border-gray-600 dark:bg-gray-700 dark:text-white focus:ring-2 focus:ring-primary-500 focus:border-primary-500"
              />
              <button
                id="refresh-patterns"
                class="px-3 py-1 text-sm bg-gray-200 dark:bg-gray-700 text-gray-700 dark:text-gray-300 rounded-md hover:bg-gray-300 dark:hover:bg-gray-600"
              >
                Refresh
              </button>
            </div>
          </div>
          <div id="patterns-list" class="space-y-3">
            <div class="text-center text-gray-500 dark:text-gray-400 py-8">
              Loading patterns...
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Instructions -->
    <div class="mt-8 rounded-lg border border-gray-200 bg-gray-50 dark:border-gray-700 dark:bg-gray-800 p-6">
      <h2 class="text-lg font-semibold text-gray-900 dark:text-white mb-3">How to Use</h2>
      <ol class="list-decimal list-inside space-y-2 text-gray-700 dark:text-gray-300">
        <li>Click the microphone button to start listening</li>
        <li>Say "Bee" followed by your question (e.g., "Bee what is fire protection?")</li>
        <li>The assistant will process your request using AI and respond</li>
        <li>Special commands:
          <ul class="list-disc list-inside ml-4 mt-1">
            <li><strong>"Bee stop"</strong> - Stop the assistant from talking</li>
            <li><strong>"Bee remember this"</strong> - Save the current conversation to memory</li>
            <li><strong>"Bee new job"</strong> or <strong>"Bee new project"</strong> - Create a new project (I'll ask you for all the details sequentially)
              <ul class="list-disc list-inside ml-4 mt-1">
                <li>For Admin/Staff: First asks if you want to use an existing client or create a new one</li>
                <li>For Clients: Starts directly with project details</li>
              </ul>
            </li>
            <li><strong>"Bee send email"</strong> or <strong>"Bee email [client name]"</strong> - Send an email. You can mention a client name like "email John Smith" or "email ABC Company" and I'll look them up automatically</li>
            <li><strong>"Bee check Gmail"</strong> - Check your Gmail inbox for new emails (requires Google OAuth with Gmail scope)</li>
            <li><strong>"Bee check emails"</strong> - Check your inbox (requires email reading setup)</li>
            <li><strong>"Bee read email"</strong> - Read a specific email (requires email reading setup)</li>
          </ul>
        </li>
        <li>Click the microphone again to stop listening</li>
      </ol>
      <p class="mt-4 text-sm text-gray-600 dark:text-gray-400">
        <strong>Note:</strong> This uses your browser's built-in speech recognition. Works best in Chrome, Edge, or Safari.
        <br />
        <strong>Note:</strong> For better accuracy and voice authentication, use the VAPI-based voice assistant at <code>/voice-assistant-vapi</code>.
        <br />
        <strong>Email Features:</strong> The assistant can send emails and monitor your Gmail inbox. Gmail monitoring automatically checks for new emails every 10 seconds and will notify you when new emails arrive. Requires Google OAuth authentication with Gmail scope. Email reading/checking for other providers requires additional setup (Outlook API or IMAP configuration).
      </p>
    </div>
  </div>
</App>

<script define:vars={{ currentUserRole: currentUser?.profile?.role || "Client" }}>
  // Voice Assistant Web Interface
  // Uses Web Speech API for speech recognition
  // Enhanced for mobile/PWA Siri-like experience

  // Detect if running as PWA (installed on home screen)
  const isPWA = window.matchMedia('(display-mode: standalone)').matches || 
                (window.navigator && window.navigator.standalone === true) ||
                document.referrer.includes('android-app://');
  
  // Detect mobile device
  const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
  
  // Apply mobile optimizations
  if (isPWA || isMobile) {
    document.documentElement.classList.add('pwa-mode');
    // Prevent zoom on double tap
    let lastTouchEnd = 0;
    document.addEventListener('touchend', (event) => {
      const now = Date.now();
      if (now - lastTouchEnd <= 300) {
        event.preventDefault();
      }
      lastTouchEnd = now;
    }, false);
    
    // Add viewport meta tag if missing
    if (!document.querySelector('meta[name="viewport"]')) {
      const viewport = document.createElement('meta');
      viewport.name = 'viewport';
      viewport.content = 'width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover';
      document.head.appendChild(viewport);
    }
  }

  // Get current user info from server
  const isClient = currentUserRole.toLowerCase() === "client";

  const micButton = document.getElementById("mic-button");
  const micIcon = document.getElementById("mic-icon");
  const statusText = document.getElementById("status-text");
  const statusIndicator = document.getElementById("status-indicator");
  const conversation = document.getElementById("conversation");
  const wakeWordInput = document.getElementById("wake-word");
  const enableSpeechCheckbox = document.getElementById("enable-speech");
  const skipWakeWordCheckbox = document.getElementById("skip-wake-word");
  const enableTagsCheckbox = document.getElementById("enable-tags");
  const fileInput = document.getElementById("file-input");
  const fileNameDisplay = document.getElementById("file-name");
  const uploadBtn = document.getElementById("upload-btn");
  const filePreview = document.getElementById("file-preview");
  const fileStatus = document.getElementById("file-status");
  
  let selectedFile = null;
  const clearButton = document.getElementById("clear-conversation");
  const btnStop = document.getElementById("btn-stop");
  const btnRemember = document.getElementById("btn-remember");
  const btnHelp = document.getElementById("btn-help");
  const tagsEditor = document.getElementById("tags-editor");
  const tagsContainer = document.getElementById("tags-container");
  const tagInput = document.getElementById("tag-input");
  const addTagBtn = document.getElementById("add-tag-btn");
  const prioritySelect = document.getElementById("priority-select");
  const btnExportLogs = document.getElementById("btn-export-logs");
  const logCountSpan = document.getElementById("log-count");
  
  let currentTags = []; // Store tags for current conversation
  let currentPriority = 0; // Store priority for current conversation
  const debugInfo = document.getElementById("debug-info");
  const debugText = document.getElementById("debug-text");
  
  // Project creation state
  let projectCreationState = null; // null | { step: string, data: object }
  let isAwaitingProjectField = false;
  
  // Debouncing and duplicate prevention
  let lastProcessedTranscript = "";
  let lastProcessedTime = 0;
  let processingCooldown = 2000; // 2 seconds cooldown between processing
  let isProcessingTranscript = false;
  
  // Logging system
  const VoiceAssistantLogger = {
    logs: [],
    maxLogs: 10000, // Maximum logs to keep in memory
    
    init() {
      // Load logs from localStorage on init
      try {
        const savedLogs = localStorage.getItem("voiceAssistantLogs");
        if (savedLogs) {
          this.logs = JSON.parse(savedLogs);
          this.updateLogCount();
        }
      } catch (error) {
        console.error("üé§ [LOGGER] Error loading logs from localStorage:", error);
      }
    },
    
    log(level, category, message, data = null) {
      const logEntry = {
        timestamp: new Date().toISOString(),
        level, // 'info', 'warn', 'error', 'debug'
        category, // 'command', 'project', 'voice', 'api', 'state', etc.
        message,
        data: data ? JSON.parse(JSON.stringify(data)) : null, // Deep clone to avoid reference issues
        userAgent: navigator.userAgent,
        url: window.location.href,
      };
      
      this.logs.push(logEntry);
      
      // Keep only the most recent logs
      if (this.logs.length > this.maxLogs) {
        this.logs = this.logs.slice(-this.maxLogs);
      }
      
      // Save to localStorage
      try {
        localStorage.setItem("voiceAssistantLogs", JSON.stringify(this.logs));
      } catch (error) {
        console.error("üé§ [LOGGER] Error saving logs to localStorage:", error);
        // If localStorage is full, remove oldest logs
        if (error.name === "QuotaExceededError") {
          this.logs = this.logs.slice(-Math.floor(this.maxLogs / 2));
          try {
            localStorage.setItem("voiceAssistantLogs", JSON.stringify(this.logs));
          } catch (e) {
            console.error("üé§ [LOGGER] Failed to save logs after cleanup:", e);
          }
        }
      }
      
      this.updateLogCount();
      
      // Also log to console with prefix
      const consoleMethod = level === "error" ? console.error : level === "warn" ? console.warn : console.log;
      consoleMethod(`üé§ [${category.toUpperCase()}] ${message}`, data || "");
    },
    
    info(category, message, data) {
      this.log("info", category, message, data);
    },
    
    warn(category, message, data) {
      this.log("warn", category, message, data);
    },
    
    error(category, message, data) {
      this.log("error", category, message, data);
    },
    
    debug(category, message, data) {
      this.log("debug", category, message, data);
    },
    
    updateLogCount() {
      if (logCountSpan) {
        logCountSpan.textContent = this.logs.length;
      }
    },
    
    exportLogs() {
      const exportData = {
        exportedAt: new Date().toISOString(),
        totalLogs: this.logs.length,
        logs: this.logs,
        summary: {
          byLevel: {},
          byCategory: {},
          errors: this.logs.filter(l => l.level === "error").length,
          warnings: this.logs.filter(l => l.level === "warn").length,
        },
      };
      
      // Calculate summaries
      this.logs.forEach(log => {
        exportData.summary.byLevel[log.level] = (exportData.summary.byLevel[log.level] || 0) + 1;
        exportData.summary.byCategory[log.category] = (exportData.summary.byCategory[log.category] || 0) + 1;
      });
      
      // Create downloadable file
      const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: "application/json" });
      const url = URL.createObjectURL(blob);
      const a = document.createElement("a");
      a.href = url;
      a.download = `voice-assistant-logs-${new Date().toISOString().replace(/:/g, "-").split(".")[0]}.json`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
      
      this.info("export", "Logs exported", { totalLogs: this.logs.length });
    },
    
    clearLogs() {
      this.logs = [];
      localStorage.removeItem("voiceAssistantLogs");
      this.updateLogCount();
      this.info("export", "Logs cleared");
    },
  };
  
  // Initialize logger
  VoiceAssistantLogger.init();
  VoiceAssistantLogger.info("system", "Voice Assistant initialized", {
    userRole: currentUserRole,
    isClient,
    userAgent: navigator.userAgent,
    tagsEnabled: enableTagsCheckbox?.checked || false,
  });
  
  // Gmail Monitoring - Check for new emails every 10 seconds
  let gmailMonitoringInterval = null;
  let lastGmailCheck = null;
  let isGmailMonitoringEnabled = false;
  
  async function checkGmailForNewEmails() {
    try {
      const response = await fetch("/api/voice-assistant/gmail-monitor", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        credentials: "include", // Include cookies for authentication
      });
      
      if (!response.ok) {
        if (response.status === 401) {
          // Not authenticated with Google - stop monitoring
          if (gmailMonitoringInterval) {
            clearInterval(gmailMonitoringInterval);
            gmailMonitoringInterval = null;
            isGmailMonitoringEnabled = false;
          }
          VoiceAssistantLogger.warn("gmail", "Gmail monitoring stopped - not authenticated with Google");
          return;
        }
        throw new Error(`HTTP ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.success && data.newEmails && data.newEmails.length > 0) {
        // New emails found!
        const emailCount = data.newEmails.length;
        const emailList = data.newEmails
          .slice(0, 3) // Only announce first 3
          .map((email) => `${email.from.split("<")[0].trim() || email.from}: ${email.subject}`)
          .join(". ");
        
        const announcement = emailCount === 1 
          ? `You have 1 new email. ${emailList}`
          : `You have ${emailCount} new emails. ${emailList}${emailCount > 3 ? ` and ${emailCount - 3} more` : ""}`;
        
        // Add to conversation
        addMessage("assistant", announcement);
        
        // Speak the announcement if speech is enabled
        if (enableSpeechCheckbox?.checked && !isListening) {
          speak(announcement);
        }
        
        VoiceAssistantLogger.info("gmail", `New emails detected: ${emailCount}`, {
          emails: data.newEmails.map((e) => ({ from: e.from, subject: e.subject })),
        });
      }
      
      lastGmailCheck = new Date();
    } catch (error) {
      VoiceAssistantLogger.error("gmail", "Error checking Gmail", { error: error.message });
    }
  }
  
  function startGmailMonitoring() {
    if (gmailMonitoringInterval) {
      return; // Already monitoring
    }
    
    VoiceAssistantLogger.info("gmail", "Starting Gmail monitoring (every 10 seconds)");
    isGmailMonitoringEnabled = true;
    
    // Check immediately
    checkGmailForNewEmails();
    
    // Then check every 10 seconds
    gmailMonitoringInterval = setInterval(checkGmailForNewEmails, 10000);
  }
  
  function stopGmailMonitoring() {
    if (gmailMonitoringInterval) {
      clearInterval(gmailMonitoringInterval);
      gmailMonitoringInterval = null;
      isGmailMonitoringEnabled = false;
      VoiceAssistantLogger.info("gmail", "Gmail monitoring stopped");
    }
  }
  
  // Start Gmail monitoring when page loads (if user is authenticated)
  // Check after a short delay to ensure cookies are available
  setTimeout(() => {
    startGmailMonitoring();
  }, 2000);
  
  // Log when tag toggle changes
  if (enableTagsCheckbox) {
    enableTagsCheckbox.addEventListener("change", (e) => {
      const enabled = e.target.checked;
      VoiceAssistantLogger.info("system", "Tag extraction toggled", { enabled });
      // Hide tags editor if disabled
      if (!enabled && tagsEditor) {
        tagsEditor.classList.add("hidden");
        currentTags = [];
        updateTagsDisplay();
      }
    });
  }
  

  let recognition = null;
  let isListening = false;
  let conversationHistory = [];
  let isAwake = false;
  let wakeWord = "Bee";
  let currentSpeechUtterance = null;

  // Check for browser support
  const SpeechRecognition =
    window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    statusText.textContent = "Speech recognition not supported in this browser";
    statusIndicator.className = "w-3 h-3 rounded-full bg-red-400";
    micButton.disabled = true;
  } else {
    recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true; // Enable interim results for better accuracy
    recognition.lang = "en-US";
    recognition.maxAlternatives = 3; // Get multiple transcription alternatives
    
    // Add grammar hints for better recognition (if supported)
    try {
      const grammar = `#JSGF V1.0; grammar wakeword; public <wakeword> = Bee | bee | B | b;`;
      const speechRecognitionList = new (window.SpeechGrammarList || window.webkitSpeechGrammarList)();
      speechRecognitionList.addFromString(grammar, 1);
      recognition.grammars = speechRecognitionList;
    } catch (e) {
      // Grammar not supported, continue without it
      console.log("Speech grammar not supported");
    }

    recognition.onstart = () => {
      isListening = true;
      updateStatus("Listening...", "bg-blue-400");
      micButton.classList.add("ring-4", "ring-blue-300", "animate-pulse");
      // Add visual feedback for mobile
      if (isMobile || isPWA) {
        micButton.style.transform = "scale(1.1)";
      }
      VoiceAssistantLogger.info("voice", "Speech recognition started");
    };

    recognition.onend = () => {
      isListening = false;
      updateStatus("Ready - Click microphone to start", "bg-gray-400");
      micButton.classList.remove("ring-4", "ring-blue-300", "animate-pulse");
      // Reset visual feedback
      if (isMobile || isPWA) {
        micButton.style.transform = "scale(1)";
      }
      VoiceAssistantLogger.debug("voice", "Speech recognition ended", { isAwake });
      
      // Auto-restart if it stopped unexpectedly (browser sometimes stops recognition)
      // Only restart if we were actively listening
      if (isAwake) {
        setTimeout(() => {
          if (!isListening) {
            try {
              recognition.start();
              VoiceAssistantLogger.debug("voice", "Speech recognition auto-restarted");
            } catch (e) {
              VoiceAssistantLogger.warn("voice", "Recognition already starting", { error: e.message });
            }
          }
        }, 100);
      }
    };

    recognition.onerror = (event) => {
      console.error("Speech recognition error:", event.error);
      VoiceAssistantLogger.error("voice", "Speech recognition error", { error: event.error, event });
      updateStatus(`Error: ${event.error}`, "bg-red-400");
      isListening = false;
    };

    recognition.onresult = async (event) => {
      
      // Prevent duplicate processing
      if (isProcessingTranscript) {
        VoiceAssistantLogger.debug("voice", "Skipping duplicate transcript processing");
        return;
      }
      
      // Get the most confident transcript from FINAL results only
      let transcript = "";
      let confidence = 0;
      let hasFinalResult = false;
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        if (result.isFinal) {
          hasFinalResult = true;
          // Use the most confident alternative
          const alternatives = Array.from(result);
          const bestAlternative = alternatives.reduce((best, current) => {
            return (current.confidence || 0) > (best.confidence || 0) ? current : best;
          });
          
          if (bestAlternative.confidence > confidence) {
            transcript = bestAlternative.transcript;
            confidence = bestAlternative.confidence;
          }
        }
        // Skip interim results - we only want final transcripts
      }
      
      // Only process if we have a final result
      if (!hasFinalResult) {
        VoiceAssistantLogger.debug("voice", "Skipping interim transcript", { 
          hasFinalResult: false 
        });
        return;
      }
      
      transcript = transcript.trim();
      if (!transcript) return;
      
      // Check for duplicate transcript (same as last processed)
      const now = Date.now();
      if (transcript.toLowerCase() === lastProcessedTranscript.toLowerCase() && 
          (now - lastProcessedTime) < processingCooldown) {
        VoiceAssistantLogger.debug("voice", "Skipping duplicate transcript", {
          transcript,
          timeSinceLastProcess: now - lastProcessedTime,
        });
        return;
      }
      
      // Post-process transcript to fix common errors
      transcript = correctCommonErrors(transcript);
      
      // Update last processed
      lastProcessedTranscript = transcript.toLowerCase();
      lastProcessedTime = now;
      isProcessingTranscript = true;
      
      VoiceAssistantLogger.info("voice", "Transcript received (final)", { 
        transcript,
        confidence,
        isFinal: true 
      });
      
      // Process the transcript
      try {
        await processTranscript(transcript);
      } finally {
        // Reset processing flag after a short delay to allow for natural speech pauses
        setTimeout(() => {
          isProcessingTranscript = false;
        }, 1500);
      }
    };
    
    // Process transcript (used by both Web Speech API and cloud transcription)
    async function processTranscript(transcript) {

      const skipWakeWord = skipWakeWordCheckbox.checked;
      const currentWakeWord = wakeWordInput.value.toLowerCase().trim();
      const transcriptLower = transcript.toLowerCase();

      // Check if wake word is in the transcript
      const wakeWordIndex = transcriptLower.indexOf(currentWakeWord);
      const hasWakeWord = wakeWordIndex !== -1;

      // Extract command (remove wake word if present)
      let command = transcript;
      if (hasWakeWord) {
        // Remove wake word and clean up
        command = transcript
          .replace(new RegExp(currentWakeWord, "gi"), "")
          .trim()
          .replace(/\s+/g, " ");
      }

      // Debug logging
      debugText.textContent = `Transcript: "${transcript}" | Command: "${command}" | HasWakeWord: ${hasWakeWord} | SkipWakeWord: ${skipWakeWord}`;
      debugInfo.classList.remove("hidden");

      // Process if: skip wake word mode OR wake word detected OR already awake
      const shouldProcess = skipWakeWord || hasWakeWord || isAwake;

      if (shouldProcess) {
        // Set awake state
        if (!isAwake && (skipWakeWord || hasWakeWord)) {
          isAwake = true;
          updateStatus("Awake - Processing...", "bg-green-400");
        }

        // Process command if there's content (or if skipping wake word)
        if (skipWakeWord ? transcript.length > 0 : command.length > 0) {
          const commandToProcess = skipWakeWord ? transcript : command;
          const commandLower = commandToProcess.toLowerCase().trim();
          
          VoiceAssistantLogger.info("command", "Processing command", {
            command: commandToProcess,
            hasWakeWord,
            skipWakeWord,
            isAwake,
          });
          
          // Extract and show tags for user message (only if enabled)
          let userTags = [];
          if (enableTagsCheckbox?.checked) {
            VoiceAssistantLogger.debug("tags", "Extracting tags from transcript");
            userTags = await extractTags(transcript);
            // Add extracted tags to current tags
            userTags.forEach(tag => addTag(tag));
            // Show tags editor
            if (tagsEditor && userTags.length > 0) {
              tagsEditor.classList.remove("hidden");
            }
          } else {
            VoiceAssistantLogger.debug("tags", "Tag extraction disabled, skipping");
          }
          addMessage("user", transcript, userTags);
          
          // Check for special keyword commands
          if (commandLower.includes("stop") || commandLower === "stop") {
            VoiceAssistantLogger.info("command", "Stop command detected");
            // Stop talking command
            stopSpeaking();
            addMessage("assistant", "Stopped speaking.");
            updateStatus("Ready - Say wake word", "bg-gray-400");
            if (!skipWakeWordCheckbox.checked) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
            return;
          }
          
          if (commandLower.includes("remember this") || commandLower.includes("remember that")) {
            // Save conversation to learning table
            VoiceAssistantLogger.info("command", "Remember command detected");
            updateStatus("Saving conversation...", "bg-purple-400");
            try {
              const saved = await saveConversation();
              if (saved) {
                VoiceAssistantLogger.info("command", "Conversation saved successfully");
                addMessage("assistant", "I've saved this conversation to my memory.");
                updateStatus("Conversation saved!", "bg-green-400");
              } else {
                VoiceAssistantLogger.warn("command", "Failed to save conversation");
                addMessage("assistant", "I couldn't save the conversation. Please check the console for errors.");
                updateStatus("Save failed", "bg-red-400");
              }
            } catch (error) {
              VoiceAssistantLogger.error("command", "Error saving conversation", { error: error.message, stack: error.stack });
              console.error("Error saving conversation:", error);
              addMessage("assistant", "I encountered an error saving the conversation.");
              updateStatus("Error saving", "bg-red-400");
            }
            
            if (!skipWakeWordCheckbox.checked) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
            return;
          }
          
          // Handle project field collection if we're in project creation mode (check this first)
          if (isAwaitingProjectField && projectCreationState) {
            // Check if this is a duplicate of the last processed input
            const normalizedInput = commandToProcess.toLowerCase().trim();
            if (normalizedInput === lastProcessedTranscript && 
                (Date.now() - lastProcessedTime) < processingCooldown) {
              VoiceAssistantLogger.debug("project", "Skipping duplicate project field input", {
                input: commandToProcess,
                step: projectCreationState.step,
              });
              return;
            }
            
            VoiceAssistantLogger.debug("project", "Handling project field input", { 
              step: projectCreationState.step,
              input: commandToProcess 
            });
            
            // Update last processed before handling
            lastProcessedTranscript = normalizedInput;
            lastProcessedTime = Date.now();
            
            await handleProjectFieldInput(commandToProcess);
            return;
          }
          
          // Check for "Bee new job" or "Bee new project" command
          if (commandLower.includes("new job") || commandLower.includes("new project")) {
            if (isAwaitingProjectField) {
              VoiceAssistantLogger.warn("project", "Project creation already in progress");
              const response = "I'm already helping you create a project. Please answer my current question, or say 'cancel' to start over.";
              addMessage("assistant", response);
              if (enableSpeechCheckbox.checked) {
                speak(response);
              }
              return;
            }
            
            VoiceAssistantLogger.info("project", "Starting project creation", { isClient, userRole: currentUserRole });
            
            // Start project creation flow
            // Reset processing state to allow new inputs
            lastProcessedTranscript = "";
            lastProcessedTime = 0;
            
            if (!isClient) {
              // Admin/Staff: Ask about client first
              projectCreationState = {
                step: "clientType",
                data: {}
              };
              isAwaitingProjectField = true;
              const response = "I'll help you create a new project. First, do you want to use an existing client or create a new client? Say 'existing' or 'new'.";
              addMessage("assistant", response);
              updateStatus("Creating project - Client selection", "bg-blue-400");
              
              // Wait before speaking to prevent immediate re-processing
              if (enableSpeechCheckbox.checked) {
                setTimeout(() => {
                  speak(response);
                }, 800);
              }
            } else {
              // Client: Start directly with address
              projectCreationState = {
                step: "address",
                data: {}
              };
              isAwaitingProjectField = true;
              const response = "I'll help you create a new project. Let's start with the project address. What's the address for this project?";
              addMessage("assistant", response);
              updateStatus("Creating project - Address", "bg-blue-400");
              
              // Wait before speaking to prevent immediate re-processing
              if (enableSpeechCheckbox.checked) {
                setTimeout(() => {
                  speak(response);
                }, 800);
              }
            }
            return;
          }
          
          // Regular command processing
          updateStatus("Processing...", "bg-yellow-400");

          try {
            VoiceAssistantLogger.info("api", "Processing command via API", { command: commandToProcess });
            console.log("Processing command:", commandToProcess);
            const response = await processCommand(commandToProcess);
            console.log("Received response:", response);
            
            VoiceAssistantLogger.info("api", "Received API response", { 
              responseLength: response?.length,
              hasResponse: !!response 
            });
            
            if (response) {
              addMessage("assistant", response);

              // Speak response if enabled
              if (enableSpeechCheckbox.checked) {
                VoiceAssistantLogger.debug("voice", "Speaking response", { responseLength: response.length });
                speak(response);
              }

              updateStatus("Ready - Say wake word", "bg-gray-400");
            } else {
              throw new Error("Empty response from API");
            }

            // Return to wake word listening after a delay (unless skip mode)
            if (!skipWakeWordCheckbox.checked) {
              setTimeout(() => {
                isAwake = false;
              }, 2000);
            }
          } catch (error) {
            VoiceAssistantLogger.error("api", "Error processing command", { 
              error: error.message, 
              stack: error.stack,
              command: commandToProcess 
            });
            console.error("Error processing command:", error);
            const errorMsg = `Sorry, I encountered an error: ${error.message || "Please try again."}`;
            addMessage("assistant", errorMsg);
            updateStatus("Error - Try again", "bg-red-400");
            if (enableSpeechCheckbox.checked) {
              speak(errorMsg);
            }
            if (!skipWakeWordCheckbox.checked) {
              isAwake = false;
            }
          }
        } else if (hasWakeWord && command.length === 0 && !skipWakeWord) {
          // Wake word detected but no command yet
          isAwake = true;
          // Extract tags even for just wake word (only if enabled)
          let userTags = [];
          if (enableTagsCheckbox?.checked) {
            VoiceAssistantLogger.debug("tags", "Extracting tags from wake word");
            userTags = await extractTags(transcript);
            // Add extracted tags to current tags
            userTags.forEach(tag => addTag(tag));
            // Show tags editor
            if (tagsEditor && userTags.length > 0) {
              tagsEditor.classList.remove("hidden");
            }
          }
          addMessage("user", transcript, userTags);
          updateStatus("Awake - Listening for command...", "bg-green-400");
          // Keep listening - don't return
        }
      }
    };
  }

  // Handle project field input sequentially
  async function handleProjectFieldInput(input) {
    if (!projectCreationState) {
      VoiceAssistantLogger.warn("project", "handleProjectFieldInput called but no projectCreationState");
      return;
    }
    
    VoiceAssistantLogger.info("project", "Processing project field input", {
      step: projectCreationState.step,
      input,
      dataKeys: Object.keys(projectCreationState.data || {}),
    });
    
    // Check for cancellation
    const inputLower = input.toLowerCase().trim();
    if (inputLower === "cancel" || inputLower === "stop" || inputLower.includes("cancel") || inputLower.includes("never mind")) {
      VoiceAssistantLogger.info("project", "Project creation cancelled by user");
      projectCreationState = null;
      isAwaitingProjectField = false;
      const cancelMsg = "Project creation cancelled. You can start again anytime by saying 'Bee new job'.";
      addMessage("assistant", cancelMsg);
      if (enableSpeechCheckbox.checked) {
        speak(cancelMsg);
      }
      updateStatus("Ready - Say wake word", "bg-gray-400");
      if (!skipWakeWordCheckbox.checked) {
        setTimeout(() => {
          isAwake = false;
        }, 2000);
      }
      return;
    }
    
    const { step, data } = projectCreationState;
    let nextStep = null;
    let response = "";
    
    // Process current step and move to next
    switch (step) {
      case "clientType":
        const clientTypeLower = input.toLowerCase().trim();
        VoiceAssistantLogger.debug("project", "Processing clientType input", { input, clientTypeLower });
        
        if (clientTypeLower.includes("existing") || clientTypeLower.includes("current") || clientTypeLower.includes("old")) {
          projectCreationState.clientType = "existing";
          nextStep = "searchClient";
          VoiceAssistantLogger.info("project", "Client type selected: existing", { nextStep });
          response = "Got it. Let's find an existing client. What's the client's name, company name, or email? I'll search for them.";
        } else if (clientTypeLower.includes("new") || clientTypeLower.includes("create")) {
          projectCreationState.clientType = "new";
          nextStep = "firstName";
          VoiceAssistantLogger.info("project", "Client type selected: new", { nextStep });
          response = "Great! Let's create a new client. What's the client's first name?";
        } else {
          // Didn't understand, ask again
          VoiceAssistantLogger.warn("project", "Unclear client type response", { input, clientTypeLower });
          response = "I didn't understand. Do you want to use an existing client or create a new client? Say 'existing' or 'new'.";
          addMessage("assistant", response);
          if (enableSpeechCheckbox.checked) {
            setTimeout(() => {
              speak(response);
            }, 500);
          }
          return; // Return early to prevent state update
        }
        break;
        
      case "searchClient":
        // Search for clients
        const searchResults = await searchClients(input.trim());
        if (searchResults.length === 0) {
          response = `I couldn't find any clients matching "${input}". Would you like to search again with different terms, or create a new client instead? Say 'search again', 'new client', or 'cancel'.`;
          nextStep = "searchClient"; // Stay on search step
        } else if (searchResults.length === 1) {
          // Single match - use it
          data.authorId = searchResults[0].id;
          data.clientName = searchResults[0].companyName || `${searchResults[0].firstName} ${searchResults[0].lastName}`;
          nextStep = "address";
          response = `Found client: ${data.clientName}. Now let's get the project details. What's the address for this project?`;
        } else {
          // Multiple matches - list them and ask to select
          projectCreationState.searchResults = searchResults;
          nextStep = "selectClient";
          const clientList = searchResults.slice(0, 5).map((c, i) => 
            `${i + 1}. ${c.companyName || `${c.firstName} ${c.lastName}`} (${c.email})`
          ).join(". ");
          response = `I found ${searchResults.length} clients. Here are the first few: ${clientList}. Which one do you want? Say the number (1-${Math.min(5, searchResults.length)}) or the company name.`;
        }
        break;
        
      case "selectClient":
        // User selecting from search results
        const selection = input.toLowerCase().trim();
        const numMatch = selection.match(/\d+/);
        let selectedClient = null;
        
        if (numMatch) {
          const index = parseInt(numMatch[0]) - 1;
          if (index >= 0 && index < projectCreationState.searchResults.length) {
            selectedClient = projectCreationState.searchResults[index];
          }
        } else {
          // Try to match by name
          selectedClient = projectCreationState.searchResults.find(c => 
            c.companyName?.toLowerCase().includes(selection) ||
            `${c.firstName} ${c.lastName}`.toLowerCase().includes(selection) ||
            c.email?.toLowerCase().includes(selection)
          );
        }
        
        if (selectedClient) {
          data.authorId = selectedClient.id;
          data.clientName = selectedClient.companyName || `${selectedClient.firstName} ${selectedClient.lastName}`;
          nextStep = "address";
          response = `Selected client: ${data.clientName}. Now let's get the project details. What's the address for this project?`;
        } else {
          response = `I couldn't match that selection. Please say the number (1-${Math.min(5, projectCreationState.searchResults.length)}) or the company name from the list.`;
          nextStep = "selectClient"; // Stay on selection step
        }
        break;
        
      case "firstName":
        data.firstName = input.trim();
        nextStep = "lastName";
        response = `First name: ${data.firstName}. What's the last name?`;
        break;
        
      case "lastName":
        data.lastName = input.trim();
        nextStep = "email";
        response = `Last name: ${data.lastName}. What's the email address?`;
        break;
        
      case "email":
        const emailMatch = input.match(/[\w\.-]+@[\w\.-]+\.\w+/);
        if (emailMatch) {
          data.email = emailMatch[0];
        } else {
          data.email = input.trim();
        }
        nextStep = "companyName";
        response = `Email: ${data.email}. What's the company name? (Say "skip" if not applicable)`;
        break;
        
      case "companyName":
        if (!input.toLowerCase().includes("skip")) {
          data.companyName = input.trim();
        }
        nextStep = "address";
        response = `Client information collected. Now let's get the project details. What's the address for this project?`;
        break;
        
      case "address":
        data.address = input.trim();
        data.title = input.trim(); // Use address as title default
        nextStep = "title";
        response = `Got it. The address is ${data.address}. Would you like to provide a different title, or should I use the address as the title?`;
        break;
        
      case "title":
        if (input.toLowerCase().includes("use address") || input.toLowerCase().includes("same") || input.toLowerCase().includes("keep")) {
          // Keep address as title
        } else {
          data.title = input.trim();
        }
        nextStep = "architect";
        response = `Title set. Who is the architect for this project? (Say "skip" if not applicable)`;
        break;
        
      case "architect":
        if (!input.toLowerCase().includes("skip")) {
          data.architect = input.trim();
        }
        nextStep = "sqFt";
        response = `Architect noted. What's the square footage of the project? (Say "skip" if not applicable)`;
        break;
        
      case "sqFt":
        if (!input.toLowerCase().includes("skip")) {
          const sqFtMatch = input.match(/\d+/);
          if (sqFtMatch) {
            data.sqFt = sqFtMatch[0];
          }
        }
        nextStep = "units";
        response = `Square footage recorded. How many units does this project have? (Say "skip" if not applicable)`;
        break;
        
      case "units":
        if (!input.toLowerCase().includes("skip")) {
          const unitsMatch = input.match(/\d+/);
          if (unitsMatch) {
            data.units = unitsMatch[0];
          }
        }
        nextStep = "newConstruction";
        response = `Units recorded. Is this new construction? (Say "yes" or "no")`;
        break;
        
      case "newConstruction":
        data.newConstruction = input.toLowerCase().includes("yes") || input.toLowerCase().includes("y");
        nextStep = "building";
        response = `New construction: ${data.newConstruction ? "Yes" : "No"}. What type of building is this? You can choose from: Residential, Mixed use, Mercantile, Commercial, Storage, Warehouse, or Institutional. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "building":
        if (!input.toLowerCase().includes("skip")) {
          const buildingTypes = ["Residential", "Mixed use", "Mercantile", "Commercial", "Storage", "Warehouse", "Institutional"];
          const selected = buildingTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.building = selected;
          }
        }
        nextStep = "project";
        response = `Building type recorded. What type of project is this? You can choose from: Sprinkler, Alarm, Mechanical, Electrical, Plumbing, Civil engineering, or Other. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "project":
        if (!input.toLowerCase().includes("skip")) {
          const projectTypes = ["Sprinkler", "Alarm", "Mechanical", "Electrical", "Plumbing", "Civil engineering", "Other"];
          const selected = projectTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.project = selected;
          }
        }
        nextStep = "tier";
        response = `Project type recorded. What tier is this? You can choose: Tier I, Tier II, or Tier III. (Say "skip" if not applicable)`;
        break;
        
      case "tier":
        if (!input.toLowerCase().includes("skip")) {
          if (input.toLowerCase().includes("tier i") || input.toLowerCase().includes("tier 1")) {
            data.tier = ["Tier I"];
          } else if (input.toLowerCase().includes("tier ii") || input.toLowerCase().includes("tier 2")) {
            data.tier = ["Tier II"];
          } else if (input.toLowerCase().includes("tier iii") || input.toLowerCase().includes("tier 3")) {
            data.tier = ["Tier III"];
          }
        }
        nextStep = "service";
        response = `Tier recorded. What's the supply or service type? Options are: Pump & Tank 300, Pump & Tank 600, 2' Copper, 4' Ductile, 6' Ductile, or Unknown. (Say "skip" if not applicable)`;
        break;
        
      case "service":
        if (!input.toLowerCase().includes("skip")) {
          const serviceTypes = ["Pump & Tank 300", "Pump & Tank 600", "Pump & Tank", "2' Copper", "4' Ductile", "6' Ductile", "Unknown"];
          const selected = serviceTypes.find(type => 
            input.toLowerCase().includes(type.toLowerCase().replace("'", ""))
          );
          if (selected) {
            data.service = selected === "Pump & Tank" ? "Pump & Tank 300" : selected;
          }
        }
        nextStep = "nfpaVersion";
        response = `Service type recorded. What NFPA version applies? Options are: 13, 13R, or 13D. (Say "skip" if not applicable)`;
        break;
        
      case "nfpaVersion":
        if (!input.toLowerCase().includes("skip")) {
          if (input.toLowerCase().includes("13r")) {
            data.nfpaVersion = "13R";
          } else if (input.toLowerCase().includes("13d")) {
            data.nfpaVersion = "13D";
          } else if (input.match(/\b13\b/)) {
            data.nfpaVersion = "13";
          }
        }
        nextStep = "requestedDocs";
        response = `NFPA version recorded. What reports are required? Options include: Narrative, Sprinkler, Alarm, Hydraulic Calculations, Fire Hydrant Flow Test, NFPA 241, IEBC, or IBC. (You can select multiple, say "skip" if not applicable)`;
        break;
        
      case "requestedDocs":
        if (!input.toLowerCase().includes("skip")) {
          const docTypes = ["Narrative", "Sprinkler", "Alarm", "Hydraulic Calculations", "Fire Hydrant Flow Test", "NFPA 241", "IEBC", "IBC"];
          const selected = docTypes.filter(type => 
            input.toLowerCase().includes(type.toLowerCase())
          );
          if (selected.length > 0) {
            data.requestedDocs = selected;
          } else {
            // Default to common ones
            data.requestedDocs = ["Narrative", "Sprinkler", "Hydraulic Calculations", "Fire Hydrant Flow Test"];
          }
        } else {
          // Default to common ones
          data.requestedDocs = ["Narrative", "Sprinkler", "Hydraulic Calculations", "Fire Hydrant Flow Test"];
        }
        nextStep = "description";
        response = `Reports required recorded. Would you like to add a description for this project? (Say "skip" if not needed)`;
        break;
        
      case "description":
        if (!input.toLowerCase().includes("skip")) {
          data.description = input.trim();
        }
        nextStep = "siteAccess";
        response = `Description added. What's the site access information? (Say "skip" if not applicable)`;
        break;
        
      case "siteAccess":
        if (!input.toLowerCase().includes("skip")) {
          data.siteAccess = input.trim();
        }
        nextStep = "commencementOfConstruction";
        response = `Site access recorded. What's the estimated commencement of construction? (Say "skip" if not applicable)`;
        break;
        
      case "commencementOfConstruction":
        if (!input.toLowerCase().includes("skip")) {
          data.commencementOfConstruction = input.trim();
        }
        nextStep = "buildingHeight";
        response = `Commencement date recorded. What's the building height? (Say "skip" if not applicable)`;
        break;
        
      case "buildingHeight":
        if (!input.toLowerCase().includes("skip")) {
          const heightMatch = input.match(/\d+/);
          if (heightMatch) {
            data.buildingHeight = heightMatch[0];
          }
        }
        nextStep = "floorsBelowGrade";
        response = `Building height recorded. How many floors below grade? (Say "skip" if not applicable)`;
        break;
        
      case "floorsBelowGrade":
        if (!input.toLowerCase().includes("skip")) {
          const floorsMatch = input.match(/\d+/);
          if (floorsMatch) {
            data.floorsBelowGrade = floorsMatch[0];
          }
        }
        nextStep = "complete";
        response = `All information collected. Creating your project now...`;
        break;
        
      case "complete":
        // Shouldn't reach here, but handle it
        return;
    }
    
        // Add assistant response
    if (!response) {
      VoiceAssistantLogger.error("project", "No response generated for step", { step, input });
      return;
    }
    
    VoiceAssistantLogger.info("project", "Adding assistant response", { 
      step, 
      nextStep, 
      responsePreview: response.substring(0, 50) + "...",
    });
    
    addMessage("assistant", response);
    
    // Update state BEFORE speaking to prevent race conditions
    if (nextStep === "complete") {
      VoiceAssistantLogger.info("project", "All project fields collected, creating project", { 
        dataKeys: Object.keys(data),
        hasAddress: !!data.address,
        hasAuthorId: !!data.authorId,
      });
      projectCreationState.step = "complete";
      updateStatus("Creating project...", "bg-purple-400");
      // Create the project
      await createProjectFromVoice(data);
    } else if (nextStep) {
      VoiceAssistantLogger.info("project", "Moving to next step", { 
        from: step, 
        to: nextStep,
        dataKeys: Object.keys(data),
        currentState: projectCreationState,
      });
      
      // Update the step in projectCreationState
      projectCreationState.step = nextStep;
      
      // Update status with readable step name
      const stepNames = {
        searchClient: "Searching for client",
        selectClient: "Selecting client",
        firstName: "Client first name",
        lastName: "Client last name",
        email: "Client email",
        companyName: "Client company",
        address: "Project address",
        title: "Project title",
        architect: "Architect",
        sqFt: "Square footage",
        units: "Units",
        newConstruction: "New construction",
        building: "Building type",
        project: "Project type",
        tier: "Tier",
        service: "Service type",
        nfpaVersion: "NFPA version",
        requestedDocs: "Reports required",
        description: "Description",
        siteAccess: "Site access",
        commencementOfConstruction: "Commencement date",
        buildingHeight: "Building height",
        floorsBelowGrade: "Floors below grade",
      };
      
      const statusText = stepNames[nextStep] || nextStep;
      updateStatus(`Creating project - ${statusText}`, "bg-blue-400");
      
      // Add a cooldown period after asking a question to prevent immediate re-processing
      // Reset the last processed transcript so the next response will be accepted
      lastProcessedTranscript = "";
      lastProcessedTime = 0;
      
      // Speak response after a brief delay to ensure state is updated
      if (enableSpeechCheckbox.checked) {
        // Wait a moment before speaking to allow user to finish
        setTimeout(() => {
          speak(response);
        }, 800);
      }
    } else {
      VoiceAssistantLogger.error("project", "No nextStep defined", { step, input, response });
    }
  }
  
  // Search for clients by name, company, or email
  async function searchClients(query) {
    VoiceAssistantLogger.info("project", "Searching for clients", { query });
    try {
      const response = await fetch(`/api/users/get?role=Client&search=${encodeURIComponent(query)}&limit=10`, {
        method: "GET",
        headers: {
          "Content-Type": "application/json",
        },
      });
      
      if (!response.ok) {
        VoiceAssistantLogger.error("project", "Client search failed", { 
          status: response.status, 
          statusText: response.statusText 
        });
        console.error("Error searching clients:", response.statusText);
        return [];
      }
      
      const data = await response.json();
      const results = data.data || [];
      VoiceAssistantLogger.info("project", "Client search completed", { 
        query, 
        resultCount: results.length 
      });
      return results;
    } catch (error) {
      VoiceAssistantLogger.error("project", "Error searching clients", { 
        error: error.message, 
        stack: error.stack,
        query 
      });
      console.error("Error searching clients:", error);
      return [];
    }
  }

  // Create project from collected voice data
  async function createProjectFromVoice(projectData) {
    VoiceAssistantLogger.info("project", "Creating project from voice data", { 
      projectDataKeys: Object.keys(projectData),
      hasAuthorId: !!projectData.authorId,
      hasAddress: !!projectData.address,
    });
    updateStatus("Creating project...", "bg-purple-400");
    
    try {
      // Ensure arrays are arrays
      if (projectData.building && !Array.isArray(projectData.building)) {
        projectData.building = [projectData.building];
      }
      if (projectData.project && !Array.isArray(projectData.project)) {
        projectData.project = [projectData.project];
      }
      if (projectData.tier && !Array.isArray(projectData.tier)) {
        projectData.tier = [projectData.tier];
      }
      if (projectData.requestedDocs && !Array.isArray(projectData.requestedDocs)) {
        projectData.requestedDocs = [projectData.requestedDocs];
      }
      
      // Convert numeric strings to numbers
      if (projectData.sqFt) projectData.sqFt = parseInt(projectData.sqFt);
      if (projectData.units) projectData.units = parseInt(projectData.units);
      if (projectData.buildingHeight) projectData.buildingHeight = parseInt(projectData.buildingHeight);
      if (projectData.floorsBelowGrade) projectData.floorsBelowGrade = parseInt(projectData.floorsBelowGrade);
      
      VoiceAssistantLogger.info("api", "Calling projects/upsert API", { 
        method: "POST",
        dataKeys: Object.keys(projectData),
      });
      
      const response = await fetch("/api/projects/upsert", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(projectData),
      });
      
      VoiceAssistantLogger.info("api", "Received projects/upsert response", { 
        status: response.status,
        ok: response.ok,
      });
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        VoiceAssistantLogger.error("api", "Project creation API error", { 
          status: response.status,
          errorData,
        });
        throw new Error(errorData.error || `Failed to create project: ${response.statusText}`);
      }
      
      const result = await response.json();
      
      if (result.success) {
        VoiceAssistantLogger.info("project", "Project created successfully", { 
          projectId: result.project?.id,
          title: result.project?.title,
          address: result.project?.address,
        });
        
        const successMsg = `Great! I've successfully created your project "${result.project.title || result.project.address}". The project ID is ${result.project.id}.`;
        addMessage("assistant", successMsg);
        if (enableSpeechCheckbox.checked) {
          speak(successMsg);
        }
        updateStatus("Project created!", "bg-green-400");
        
        // Reset project creation state
        projectCreationState = null;
        isAwaitingProjectField = false;
        
        if (!skipWakeWordCheckbox.checked) {
          setTimeout(() => {
            isAwake = false;
          }, 3000);
        }
      } else {
        VoiceAssistantLogger.error("project", "Project creation failed", { 
          error: result.error,
          result,
        });
        throw new Error(result.error || "Failed to create project");
      }
    } catch (error) {
      VoiceAssistantLogger.error("project", "Error creating project", { 
        error: error.message,
        stack: error.stack,
        projectData: projectData,
      });
      console.error("Error creating project:", error);
      const errorMsg = `Sorry, I encountered an error creating the project: ${error.message || "Please try again."}`;
      addMessage("assistant", errorMsg);
      updateStatus("Error creating project", "bg-red-400");
      if (enableSpeechCheckbox.checked) {
        speak(errorMsg);
      }
      
      // Reset project creation state on error
      projectCreationState = null;
      isAwaitingProjectField = false;
      
      if (!skipWakeWordCheckbox.checked) {
        setTimeout(() => {
          isAwake = false;
        }, 3000);
      }
    }
  }

  // Process command via API
  async function processCommand(text) {
    console.log("Sending to API:", { text, historyLength: conversationHistory.length });
    
    const response = await fetch("/api/voice-assistant/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        message: text,
        conversationHistory: conversationHistory.slice(-10), // Last 10 exchanges
      }),
    });

    console.log("API response status:", response.status);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(errorData.error || `API error: ${response.statusText}`);
    }

    const data = await response.json();
    console.log("API response data:", data);
    
    if (data.error) {
      throw new Error(data.error);
    }
    
    return data.response || "I'm not sure how to respond to that.";
  }

  // Add tag to current tags and update UI
  function addTag(tag) {
    const normalizedTag = tag.toLowerCase().trim();
    if (normalizedTag && !currentTags.includes(normalizedTag)) {
      currentTags.push(normalizedTag);
      updateTagsDisplay();
    }
  }

  // Remove tag from current tags
  function removeTag(tag) {
    currentTags = currentTags.filter(t => t !== tag);
    updateTagsDisplay();
  }

  // Update tags display in editor
  function updateTagsDisplay() {
    tagsContainer.innerHTML = "";
    
    if (currentTags.length === 0) {
      const emptyMsg = document.createElement("div");
      emptyMsg.className = "text-sm text-gray-400 italic";
      emptyMsg.textContent = "No tags yet. Add tags above or they'll be auto-extracted.";
      tagsContainer.appendChild(emptyMsg);
      return;
    }

    currentTags.forEach(tag => {
      const tagDiv = document.createElement("div");
      tagDiv.className = "inline-flex items-center gap-1 px-2 py-1 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 rounded text-sm";
      
      const tagSpan = document.createElement("span");
      tagSpan.textContent = `#${tag}`;
      
      const removeBtn = document.createElement("button");
      removeBtn.className = "ml-1 text-blue-600 dark:text-blue-300 hover:text-blue-800 dark:hover:text-blue-100 font-bold";
      removeBtn.textContent = "√ó";
      removeBtn.title = "Remove tag";
      removeBtn.onclick = () => removeTag(tag);
      
      tagDiv.appendChild(tagSpan);
      tagDiv.appendChild(removeBtn);
      tagsContainer.appendChild(tagDiv);
    });
  }

  // Add message to conversation
  function addMessage(role, text, tags = []) {
    conversationHistory.push({ role, content: text });

    // Add tags to current tags if provided
    if (tags && tags.length > 0) {
      tags.forEach(tag => addTag(tag));
      // Show tags editor if tags are present
      if (tagsEditor) {
        tagsEditor.classList.remove("hidden");
      }
    }

    // Clear placeholder
    if (conversation.querySelector(".text-gray-500")) {
      conversation.innerHTML = "";
    }

    const messageDiv = document.createElement("div");
    messageDiv.className = `flex ${role === "user" ? "justify-end" : "justify-start"} mb-2`;

    const bubble = document.createElement("div");
    bubble.className = `max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
      role === "user"
        ? "bg-primary-600 text-white"
        : role === "system"
        ? "bg-yellow-100 dark:bg-yellow-900 text-yellow-800 dark:text-yellow-200 border border-yellow-300 dark:border-yellow-700"
        : "bg-gray-200 dark:bg-gray-700 text-gray-900 dark:text-white"
    }`;

    bubble.textContent = text;
    
    // Add tags display if present (read-only in conversation)
    if (tags && tags.length > 0) {
      const tagsDiv = document.createElement("div");
      tagsDiv.className = "mt-2 flex flex-wrap gap-1";
      tags.forEach(tag => {
        const tagSpan = document.createElement("span");
        tagSpan.className = "text-xs px-2 py-1 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 rounded";
        tagSpan.textContent = `#${tag}`;
        tagsDiv.appendChild(tagSpan);
      });
      bubble.appendChild(tagsDiv);
    }
    
    messageDiv.appendChild(bubble);
    conversation.appendChild(messageDiv);
    conversation.scrollTop = conversation.scrollHeight;
  }
  
  // Extract and display tags for user messages
  async function processMessageWithTags(role, text) {
    if (role === "user") {
      // Extract tags from user message
      const tags = await extractTags(text);
      if (tags.length > 0) {
        addMessage(role, text, tags);
        // Show tags in debug
        debugText.textContent += ` | Tags: ${tags.join(", ")}`;
      } else {
        addMessage(role, text);
      }
    } else {
      addMessage(role, text);
    }
  }

  // Update status
  function updateStatus(text, indicatorColor) {
    statusText.textContent = text;
    statusIndicator.className = `w-3 h-3 rounded-full ${indicatorColor}`;
  }

  // Get preferred voice (prioritize natural, neural, and premium voices)
  function getPreferredVoice() {
    if (!("speechSynthesis" in window)) return null;
    
    const voices = window.speechSynthesis.getVoices();
    if (voices.length === 0) return null;
    
    // Prioritize neural/premium voices (most natural-sounding)
    const neuralVoices = [
      "Microsoft Aria", // Neural voice - very natural
      "Microsoft Jenny", // Neural voice - very natural
      "Microsoft Aria Neural", // Neural voice
      "Microsoft Jenny Neural", // Neural voice
      "Google en-US-Neural2", // Google Neural
      "Google en-US-Neural2-C", // Google Neural
      "Google en-US-Neural2-D", // Google Neural
      "Google en-US-Neural2-E", // Google Neural
      "Google en-US-Neural2-F", // Google Neural
      "Google en-US-Neural2-G", // Google Neural
      "Google en-US-Neural2-H", // Google Neural
      "Google en-US-Neural2-I", // Google Neural
      "Google en-US-Neural2-J", // Google Neural
    ];
    
    // High-quality natural voices (second priority)
    const naturalVoices = [
      "Samantha", // macOS - very natural
      "Victoria", // macOS - very natural
      "Karen", // macOS - natural
      "Alex", // macOS - natural
      "Microsoft Zira", // Windows - natural
      "Microsoft Hazel", // Windows - natural
      "Microsoft Aria", // Windows - natural
      "Microsoft Jenny", // Windows - natural
      "Google UK English Female",
      "Google US English Female",
      "Google Australian English Female",
    ];
    
    // Try neural voices first (most natural)
    for (const voiceName of neuralVoices) {
      const voice = voices.find(v => 
        v.name.includes(voiceName) || 
        v.name.toLowerCase().includes(voiceName.toLowerCase())
      );
      if (voice) {
        console.log("üé§ Using neural voice:", voice.name);
        return voice;
      }
    }
    
    // Try natural voices (second choice)
    for (const voiceName of naturalVoices) {
      const voice = voices.find(v => 
        v.name.includes(voiceName) || 
        v.name.toLowerCase().includes(voiceName.toLowerCase())
      );
      if (voice) {
        console.log("üé§ Using natural voice:", voice.name);
        return voice;
      }
    }
    
    // Fallback: find any voice with "neural" in the name
    const anyNeural = voices.find(v => 
      v.name.toLowerCase().includes("neural")
    );
    if (anyNeural) {
      console.log("üé§ Using neural voice (fallback):", anyNeural.name);
      return anyNeural;
    }
    
    // Fallback: find any female voice
    const femaleVoice = voices.find(v => 
      v.name.toLowerCase().includes("female") ||
      v.name.includes("Samantha") ||
      v.name.includes("Victoria") ||
      v.name.includes("Karen") ||
      v.name.includes("Zira") ||
      v.name.includes("Hazel") ||
      v.name.includes("Aria") ||
      v.name.includes("Jenny")
    );
    if (femaleVoice) {
      console.log("üé§ Using female voice (fallback):", femaleVoice.name);
      return femaleVoice;
    }
    
    // Last resort: use default voice
    console.log("üé§ Using default voice:", voices[0]?.name);
    return voices[0];
  }

  // Speak text
  function speak(text) {
    if ("speechSynthesis" in window) {
      VoiceAssistantLogger.debug("voice", "Speaking text", { 
        textLength: text.length,
        textPreview: text.substring(0, 50) + (text.length > 50 ? "..." : ""),
      });
      
      // Stop any current speech
      stopSpeaking();
      
      // Process text for more natural speech (add slight pauses after punctuation)
      const processedText = text
        .replace(/\. /g, '. ') // Keep periods with space
        .replace(/, /g, ', ') // Keep commas with space
        .replace(/\? /g, '? ') // Keep question marks with space
        .replace(/! /g, '! '); // Keep exclamation marks with space
      
      const utterance = new SpeechSynthesisUtterance(processedText);
      
      // Set natural speaking rate (0.95 = slightly slower than normal for clarity, but not robotic)
      // Normal rate is 1.0, so 0.95 is just slightly slower for better comprehension
      utterance.rate = 0.95;
      
      // Normal pitch for natural sound (1.0 = normal human pitch)
      utterance.pitch = 1.0;
      
      // Normal volume
      utterance.volume = 1.0;
      
      // Set preferred voice
      const preferredVoice = getPreferredVoice();
      if (preferredVoice) {
        utterance.voice = preferredVoice;
        VoiceAssistantLogger.debug("voice", "Using voice", { voiceName: preferredVoice.name });
      }
      
      utterance.onstart = () => {
        VoiceAssistantLogger.debug("voice", "Speech started");
      };
      
      utterance.onend = () => {
        VoiceAssistantLogger.debug("voice", "Speech ended");
      };
      
      utterance.onerror = (event) => {
        VoiceAssistantLogger.error("voice", "Speech synthesis error", { 
          error: event.error,
          type: event.type,
        });
      };
      
      currentSpeechUtterance = utterance;
      window.speechSynthesis.speak(utterance);
    } else {
      VoiceAssistantLogger.warn("voice", "Speech synthesis not available");
    }
  }
  
  // Load voices when they become available (some browsers need this)
  if ("speechSynthesis" in window) {
    // Load voices immediately if available
    if (window.speechSynthesis.getVoices().length > 0) {
      // Voices already loaded
    } else {
      // Wait for voices to load
      window.speechSynthesis.onvoiceschanged = () => {
        console.log("Voices loaded:", window.speechSynthesis.getVoices().length);
      };
    }
  }

  // Stop speaking
  function stopSpeaking() {
    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel();
      currentSpeechUtterance = null;
    }
  }

  // Extract tags from text using AI
  async function extractTags(text) {
    try {
      const response = await fetch("/api/voice-assistant/extract-tags", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ text }),
      });

      if (!response.ok) {
        console.error("Tag extraction failed");
        return [];
      }

      const data = await response.json();
      return data.tags || [];
    } catch (error) {
      console.error("Error extracting tags:", error);
      return [];
    }
  }

  // Save conversation to learning table
  async function saveConversation() {
    if (conversationHistory.length === 0) {
      console.log("No conversation to save");
      return false;
    }

    // Get the last exchange (user question + assistant response)
    const lastExchange = conversationHistory.slice(-2);
    if (lastExchange.length < 2) {
      console.log("Not enough conversation to save");
      return false;
    }

    const userMessage = lastExchange.find(m => m.role === "user")?.content || "";
    const assistantMessage = lastExchange.find(m => m.role === "assistant")?.content || "";

    if (!userMessage || !assistantMessage) {
      console.log("Missing user or assistant message");
      return false;
    }

    // Create a knowledge entry from the conversation
    const title = userMessage.substring(0, 100) + (userMessage.length > 100 ? "..." : "");
    const content = `User asked: "${userMessage}"\n\nAssistant responded: "${assistantMessage}"`;

    // Use current tags (from manual entry + auto-extraction), or extract if none (only if enabled)
    let tagsToSave = [...currentTags];
    
    if (tagsToSave.length === 0 && enableTagsCheckbox?.checked) {
      // Auto-extract tags if none manually added and tags are enabled
      const combinedText = `${userMessage} ${assistantMessage}`;
      const extractedTags = await extractTags(combinedText);
      tagsToSave = extractedTags;
      // Add extracted tags to current tags for display
      extractedTags.forEach(tag => addTag(tag));
    }
    
    // Get priority from dropdown
    const priority = parseInt(prioritySelect?.value || "0", 10);
    currentPriority = priority;
    
    console.log("Saving with tags:", tagsToSave, "and priority:", priority);

    try {
      const response = await fetch("/api/voice-assistant/remember", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          title,
          content,
          category: "conversation_memory",
          tags: tagsToSave, // Use current tags (manual + auto-extracted)
          priority: priority, // Include priority
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.error || `API error: ${response.statusText}`);
      }

      const data = await response.json();
      console.log("Conversation saved with tags and priority:", data);
      
      // Show confirmation with tags and priority
      const priorityLabels = { 0: "Normal", 1: "Low", 5: "Medium", 10: "High", 20: "Critical" };
      const priorityLabel = priorityLabels[priority] || `Priority ${priority}`;
      
      if (tagsToSave.length > 0) {
        const tagsDisplay = tagsToSave.map(tag => `#${tag}`).join(" ");
        addMessage("system", `Conversation saved with tags: ${tagsDisplay} (Priority: ${priorityLabel})`);
      } else {
        addMessage("system", `Conversation saved (Priority: ${priorityLabel})`);
      }
      
      // Clear tags and reset priority after saving
      currentTags = [];
      currentPriority = 0;
      updateTagsDisplay();
      if (prioritySelect) {
        prioritySelect.value = "0";
      }
      
      return true;
    } catch (error) {
      console.error("Error saving conversation:", error);
      return false;
    }
  }


  // Toggle listening
  micButton.addEventListener("click", async () => {
    if (!recognition) return;

    if (isListening) {
      recognition.stop();
      isAwake = false;
    } else {
      recognition.start();
    }
  });
  

  // Post-process transcript to fix common errors
  function correctCommonErrors(text) {
    let corrected = text;
    
    // Common transcription errors and corrections
    const corrections = {
      // Wake word variations
      "be": "Bee",
      "b": "Bee",
      "bee": "Bee",
      
      // Common word errors
      "what's": "what is",
      "whats": "what is",
      "that's": "that is",
      "thats": "that is",
      "it's": "it is",
      "its": "it is",
      "you're": "you are",
      "youre": "you are",
      "I'm": "I am",
      "im": "I am",
      
      // Technical terms that are often misheard
      "nfpa": "NFPA",
      "n f p a": "NFPA",
      "n f p": "NFPA",
      "fire protection": "fire protection",
      "fire alarm": "fire alarm",
      "fire sprinkler": "fire sprinkler",
      
      // Number corrections
      "one": "1",
      "two": "2",
      "three": "3",
      "four": "4",
      "five": "5",
      
      // Common phrase corrections
      "remember this": "remember this",
      "remember that": "remember this",
      "stop talking": "stop",
      "stop speaking": "stop",
    };
    
    // Apply corrections (case-insensitive)
    Object.keys(corrections).forEach((error) => {
      const regex = new RegExp(`\\b${error}\\b`, "gi");
      corrected = corrected.replace(regex, corrections[error]);
    });
    
    // Fix double spaces
    corrected = corrected.replace(/\s+/g, " ");
    
    return corrected.trim();
  }

  // Update wake word
  wakeWordInput.addEventListener("change", (e) => {
    wakeWord = e.target.value.toLowerCase().trim();
  });

  // Stop button handler
  btnStop.addEventListener("click", () => {
    stopSpeaking();
    addMessage("assistant", "Stopped speaking.");
    updateStatus("Ready - Say wake word", "bg-gray-400");
    isAwake = false;
  });

  // Remember button handler
  btnRemember.addEventListener("click", async () => {
    updateStatus("Saving conversation...", "bg-purple-400");
    try {
      const saved = await saveConversation();
      if (saved) {
        addMessage("assistant", "I've saved this conversation to my memory.");
        updateStatus("Conversation saved!", "bg-green-400");
      } else {
        addMessage("assistant", "I couldn't save the conversation. Please check the console for errors.");
        updateStatus("Save failed", "bg-red-400");
      }
    } catch (error) {
      console.error("Error saving conversation:", error);
      addMessage("assistant", "I encountered an error saving the conversation.");
      updateStatus("Error saving", "bg-red-400");
    }
  });

  // Export logs button handler
  btnExportLogs.addEventListener("click", () => {
    VoiceAssistantLogger.info("export", "Exporting logs");
    VoiceAssistantLogger.exportLogs();
  });

  // Help button handler
  btnHelp.addEventListener("click", () => {
    VoiceAssistantLogger.info("command", "Help button clicked");
    const helpText = `Here's what I can do:

üé§ Voice Commands:
‚Ä¢ "Bee [your question]" - Ask me anything
‚Ä¢ "Bee stop" - Stop me from talking
‚Ä¢ "Bee remember this" - Save our conversation
‚Ä¢ "Bee new job" or "Bee new project" - Create a new project (I'll ask you for all the details)
  - For Admin/Staff: I'll first ask if you want to use an existing client or create a new one
  - For Clients: I'll start directly with project details

üí° Tips:
‚Ä¢ Speak clearly for best results
‚Ä¢ Enable cloud transcription for better accuracy
‚Ä¢ Use the buttons below if voice recognition fails

üîß Available Actions:
‚Ä¢ Stop Speaking - Interrupts my speech
‚Ä¢ Remember This - Saves conversation to memory
‚Ä¢ Help - Shows this message`;

    addMessage("assistant", helpText);
    if (enableSpeechCheckbox.checked) {
      speak("Here's what I can do. Use Bee followed by your question, or say Bee stop to stop me from talking, or Bee remember this to save our conversation, or Bee new job to create a new project.");
    }
  });

  // Add tag button handler
  addTagBtn.addEventListener("click", () => {
    const tagValue = tagInput.value.trim();
    if (tagValue) {
      addTag(tagValue);
      tagInput.value = "";
      // Show tags editor if hidden
      if (tagsEditor) {
        tagsEditor.classList.remove("hidden");
      }
    }
  });

  // Add tag on Enter key
  tagInput.addEventListener("keypress", (e) => {
    if (e.key === "Enter") {
      e.preventDefault();
      addTagBtn.click();
    }
  });

  // Clear conversation
  // File upload handlers
  if (fileInput && uploadBtn && fileNameDisplay) {
    fileInput.addEventListener("change", (e) => {
      const target = e.target;
      const file = target && target.files && target.files[0];
      if (file) {
        selectedFile = file;
        fileNameDisplay.textContent = file.name;
        uploadBtn.disabled = false;
        
        // Show preview for images
        if (file.type.startsWith("image/") && filePreview) {
          const reader = new FileReader();
          reader.onload = (event) => {
            const result = event.target && event.target.result;
            if (result) {
              filePreview.innerHTML = `
                <img src="${result}" alt="Preview" class="max-w-full max-h-48 rounded-lg border border-gray-300 dark:border-gray-600">
              `;
              filePreview.classList.remove("hidden");
            }
          };
          reader.readAsDataURL(file);
        } else if (filePreview) {
          filePreview.classList.add("hidden");
        }
        
        if (fileStatus) {
          fileStatus.textContent = "";
          fileStatus.className = "mt-2 text-sm";
        }
      }
    });

    uploadBtn.addEventListener("click", async () => {
      if (!selectedFile) return;
      await processFile(selectedFile);
    });
  }

  // Process uploaded file
  async function processFile(file) {
    if (!file || !uploadBtn || !fileStatus) return;
    
    uploadBtn.disabled = true;
    fileStatus.textContent = "Processing file...";
    fileStatus.className = "mt-2 text-sm text-blue-600 dark:text-blue-400";
    
    // Create AbortController for timeout
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 120000); // 2 minute timeout
    
    try {
      const formData = new FormData();
      formData.append("file", file);
      
      const response = await fetch("/api/voice-assistant/process-file", {
        method: "POST",
        credentials: "include",
        body: formData,
        signal: controller.signal,
      });
      
      clearTimeout(timeoutId);
      const result = await response.json();
      
      if (!response.ok) {
        throw new Error(result.error || "Failed to process file");
      }
      
      // Display extracted content
      if (result.data && result.data.content) {
        fileStatus.textContent = "File processed successfully!";
        fileStatus.className = "mt-2 text-sm text-green-600 dark:text-green-400";
        
        // Add extracted content to conversation
        addMessage("system", `üìÑ File "${file.name}" processed successfully. Extracted content:`, []);
        
        // Show extracted text (strip HTML for display)
        const textContent = result.data.content.replace(/<[^>]*>/g, "").substring(0, 500);
        addMessage("assistant", textContent + (result.data.content.length > 500 ? "..." : ""), []);
        
        // Show detected fields if any
        if (result.data.fields && result.data.fields.length > 0) {
          const fieldsText = result.data.fields
            .map(function(f) { return `${f.name}: ${f.value},`; })
            .join("\n");
          addMessage("assistant", `\nDetected fields:\n${fieldsText}`, []);
          VoiceAssistantLogger.info("file", "Fields extracted from file", { 
            fileName: file.name, 
            fieldCount: result.data.fields.length,
            fields: result.data.fields 
          });
        }
        
        VoiceAssistantLogger.info("file", "File processed successfully", { 
          fileName: file.name, 
          fileType: file.type,
          contentLength: result.data.content.length,
          fieldCount: (result.data.fields && result.data.fields.length) || 0
        });
      } else {
        throw new Error("No content extracted from file");
      }
    } catch (error) {
      clearTimeout(timeoutId);
      console.error("[VOICE-ASSISTANT] Error processing file:", error);
      let errorMessage = "Unknown error";
      if (error.name === "AbortError") {
        errorMessage = "Request timed out. The file may be too large or complex. Try a smaller file or simpler format.";
      } else if (error && error.message) {
        errorMessage = error.message;
      }
      fileStatus.textContent = `Error: ${errorMessage}`;
      fileStatus.className = "mt-2 text-sm text-red-600 dark:text-red-400";
      addMessage("system", `‚ùå Failed to process file: ${errorMessage}`, []);
      VoiceAssistantLogger.error("file", "File processing failed", { 
        fileName: file.name, 
        error: errorMessage 
      });
    } finally {
      if (uploadBtn) uploadBtn.disabled = false;
    }
  }

  clearButton.addEventListener("click", () => {
    conversationHistory = [];
    currentTags = [];
    currentPriority = 0;
    projectCreationState = null;
    isAwaitingProjectField = false;
    selectedFile = null;
    if (fileInput) fileInput.value = "";
    if (fileNameDisplay) fileNameDisplay.textContent = "No file selected";
    if (filePreview) filePreview.classList.add("hidden");
    if (fileStatus) {
      fileStatus.textContent = "";
      fileStatus.className = "mt-2 text-sm";
    }
    conversation.innerHTML =
      '<div class="text-sm text-gray-500 dark:text-gray-400 text-center">Your conversation will appear here...</div>';
    updateTagsDisplay();
    if (prioritySelect) {
      prioritySelect.value = "0";
    }
    if (tagsEditor) {
      tagsEditor.classList.add("hidden");
    }
    isAwake = false;
    updateStatus("Ready - Click microphone to start", "bg-gray-400");
  });

  // ===== PATTERNS MANAGEMENT =====
  const togglePatternsBtn = document.getElementById("toggle-patterns");
  const patternsSection = document.getElementById("patterns-section");
  const patternsToggleText = document.getElementById("patterns-toggle-text");
  const patternForm = document.getElementById("pattern-form");
  const patternsList = document.getElementById("patterns-list");
  const patternSearch = document.getElementById("pattern-search");
  const refreshPatternsBtn = document.getElementById("refresh-patterns");

  let patterns = [];
  let editingPatternId = null;

  // Toggle patterns section
  togglePatternsBtn?.addEventListener("click", () => {
    const isHidden = patternsSection?.classList.contains("hidden");
    if (isHidden) {
      patternsSection?.classList.remove("hidden");
      patternsToggleText.textContent = "Hide";
      loadPatterns();
    } else {
      patternsSection?.classList.add("hidden");
      patternsToggleText.textContent = "Show";
    }
  });

  // Load patterns from API
  async function loadPatterns() {
    try {
      patternsList.innerHTML = '<div class="text-center text-gray-500 dark:text-gray-400 py-8">Loading patterns...</div>';
      
      const response = await fetch("/api/agent/knowledge?category=pattern&limit=100");
      const data = await response.json();
      
      if (data.success && data.entries) {
        patterns = data.entries;
        renderPatterns(patterns);
      } else {
        patternsList.innerHTML = '<div class="text-center text-red-500 py-8">Failed to load patterns</div>';
      }
    } catch (error) {
      console.error("Error loading patterns:", error);
      patternsList.innerHTML = '<div class="text-center text-red-500 py-8">Error loading patterns</div>';
    }
  }

  // Render patterns list
  function renderPatterns(patternList) {
    if (patternList.length === 0) {
      patternsList.innerHTML = '<div class="text-center text-gray-500 dark:text-gray-400 py-8">No patterns saved yet. Add one above!</div>';
      return;
    }

    patternsList.innerHTML = patternList.map(pattern => `
      <div class="border border-gray-200 dark:border-gray-700 rounded-lg p-4 bg-white dark:bg-gray-800" data-pattern-id="${pattern.id}">
        <div class="flex items-start justify-between mb-2">
          <div class="flex-1">
            <h4 class="font-semibold text-gray-900 dark:text-white">${escapeHtml(pattern.title)}</h4>
            <p class="text-sm text-gray-600 dark:text-gray-400 mt-1">${escapeHtml(pattern.content.substring(0, 150))}${pattern.content.length > 150 ? '...' : ''}</p>
            <div class="flex items-center gap-3 mt-2 text-xs text-gray-500 dark:text-gray-400">
              ${pattern.category ? `<span class="px-2 py-1 bg-gray-100 dark:bg-gray-700 rounded">${escapeHtml(pattern.category)}</span>` : ''}
              ${pattern.tags && pattern.tags.length > 0 ? `<span>Tags: ${pattern.tags.map(t => escapeHtml(t)).join(', ')}</span>` : ''}
              <span>Priority: ${pattern.priority || 0}</span>
              ${pattern.isActive === false ? '<span class="text-red-500">(Inactive)</span>' : ''}
            </div>
          </div>
          <div class="flex gap-2 ml-4">
            <button
              class="edit-pattern px-3 py-1 text-xs bg-blue-600 text-white rounded hover:bg-blue-700"
              data-id="${pattern.id}"
              title="Edit pattern"
            >
              Edit
            </button>
            <button
              class="delete-pattern px-3 py-1 text-xs bg-red-600 text-white rounded hover:bg-red-700"
              data-id="${pattern.id}"
              title="Delete pattern"
            >
              Delete
            </button>
          </div>
        </div>
      </div>
    `).join('');

    // Add event listeners
    document.querySelectorAll('.edit-pattern').forEach(btn => {
      btn.addEventListener('click', (e) => {
        const id = e.target.getAttribute('data-id');
        editPattern(id);
      });
    });

    document.querySelectorAll('.delete-pattern').forEach(btn => {
      btn.addEventListener('click', (e) => {
        const id = e.target.getAttribute('data-id');
        deletePattern(id);
      });
    });
  }

  // Escape HTML to prevent XSS
  function escapeHtml(text) {
    const div = document.createElement('div');
    div.textContent = text;
    return div.innerHTML;
  }

  // Add/Edit pattern
  patternForm?.addEventListener("submit", async (e) => {
    e.preventDefault();
    
    const title = document.getElementById("pattern-title").value.trim();
    const content = document.getElementById("pattern-content").value.trim();
    const category = document.getElementById("pattern-category").value.trim() || "pattern";
    const priority = parseInt(document.getElementById("pattern-priority").value) || 0;
    const tagsInput = document.getElementById("pattern-tags").value.trim();
    const tags = tagsInput ? tagsInput.split(',').map(t => t.trim()).filter(t => t) : [];

    if (!title || !content) {
      alert("Title and content are required");
      return;
    }

    try {
      const url = editingPatternId 
        ? `/api/agent/knowledge?id=${editingPatternId}`
        : '/api/agent/knowledge';
      
      const method = editingPatternId ? 'PUT' : 'POST';
      const body = editingPatternId
        ? { title, content, category, tags, priority }
        : { title, content, category, tags, priority };

      const response = await fetch(url, {
        method,
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
      });

      const data = await response.json();

      if (data.success) {
        // Show success message before resetting
        const action = editingPatternId ? 'updated' : 'saved';
        addMessage("system", `‚úÖ Pattern "${title}" ${action} successfully!`, []);
        
        // Reset form
        patternForm.reset();
        document.getElementById("pattern-category").value = "pattern";
        document.getElementById("pattern-priority").value = "0";
        editingPatternId = null;
        
        // Reload patterns
        await loadPatterns();
      } else {
        alert(`Error: ${data.error || 'Failed to save pattern'}`);
      }
    } catch (error) {
      console.error("Error saving pattern:", error);
      alert("Failed to save pattern. Please try again.");
    }
  });

  // Edit pattern
  function editPattern(id) {
    const pattern = patterns.find(p => p.id === id);
    if (!pattern) return;

    editingPatternId = id;
    document.getElementById("pattern-title").value = pattern.title;
    document.getElementById("pattern-content").value = pattern.content;
    document.getElementById("pattern-category").value = pattern.category || "pattern";
    document.getElementById("pattern-priority").value = pattern.priority || 0;
    document.getElementById("pattern-tags").value = pattern.tags ? pattern.tags.join(', ') : '';

    // Scroll to form
    patternForm?.scrollIntoView({ behavior: 'smooth', block: 'start' });
    patternForm?.querySelector('input')?.focus();
  }

  // Delete pattern
  async function deletePattern(id) {
    if (!confirm("Are you sure you want to delete this pattern?")) {
      return;
    }

    try {
      const response = await fetch(`/api/agent/knowledge?id=${id}`, {
        method: 'DELETE',
      });

      const data = await response.json();

      if (data.success) {
        await loadPatterns();
        addMessage("system", "‚úÖ Pattern deleted successfully!", []);
      } else {
        alert(`Error: ${data.error || 'Failed to delete pattern'}`);
      }
    } catch (error) {
      console.error("Error deleting pattern:", error);
      alert("Failed to delete pattern. Please try again.");
    }
  }

  // Search patterns
  patternSearch?.addEventListener("input", (e) => {
    const searchTerm = e.target.value.toLowerCase();
    const filtered = patterns.filter(p => 
      p.title.toLowerCase().includes(searchTerm) ||
      p.content.toLowerCase().includes(searchTerm) ||
      (p.tags && p.tags.some(t => t.toLowerCase().includes(searchTerm)))
    );
    renderPatterns(filtered);
  });

  // Refresh patterns
  refreshPatternsBtn?.addEventListener("click", () => {
    loadPatterns();
  });
</script>

<style>
  /* Mobile/PWA optimizations */
  .pwa-mode {
    /* Full-screen PWA support */
    --safe-area-inset-top: env(safe-area-inset-top);
    --safe-area-inset-bottom: env(safe-area-inset-bottom);
  }

  /* Prevent text selection on mobile for better UX */
  @media (max-width: 640px) {
    #mic-button {
      -webkit-user-select: none;
      user-select: none;
      -webkit-touch-callout: none;
    }
  }

  /* Enhanced conversation area for mobile */
  #conversation {
    scrollbar-width: thin;
    scrollbar-color: rgba(156, 163, 175, 0.5) transparent;
    /* Better mobile scrolling */
    -webkit-overflow-scrolling: touch;
  }

  #conversation::-webkit-scrollbar {
    width: 6px;
  }

  #conversation::-webkit-scrollbar-track {
    background: transparent;
  }

  #conversation::-webkit-scrollbar-thumb {
    background-color: rgba(156, 163, 175, 0.5);
    border-radius: 3px;
  }

  /* Mobile-specific styles */
  @media (max-width: 640px) {
    #voice-assistant-container {
      padding: 1rem;
    }
    
    /* Larger tap targets on mobile */
    button, input, select {
      min-height: 44px; /* iOS recommended tap target size */
    }
    
    /* Better spacing on mobile */
    .mb-8 {
      margin-bottom: 1.5rem;
    }
  }

  /* PWA full-screen mode */
  @media (display-mode: standalone) {
    #voice-assistant-container {
      padding-top: max(1rem, env(safe-area-inset-top));
      padding-bottom: max(1rem, env(safe-area-inset-bottom));
    }
  }

  /* Smooth animations for voice feedback */
  @keyframes pulse-ring {
    0% {
      transform: scale(1);
      opacity: 1;
    }
    100% {
      transform: scale(1.2);
      opacity: 0;
    }
  }

  #mic-button.animate-pulse::before {
    content: '';
    position: absolute;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    border: 3px solid rgba(59, 130, 246, 0.5);
    animation: pulse-ring 1.5s ease-out infinite;
  }
</style>

