"use strict";exports.id=3002,exports.ids=[3002],exports.modules={63002:(a,b,c)=>{c.d(b,{L6:()=>L,ks:()=>M,GB:()=>r,S7:()=>F});var d=c(29021),e=c.n(d),f=c(33873),g=c.n(f),h=c(55511),i=c.n(h),j=c(20942),k=c(21820),l=c.n(k);function m(a){e().existsSync(a)||e().mkdirSync(a,{recursive:!0})}var n=c(68570),o=c(35552);async function p(a){return new Promise((b,c)=>{let d=i().createHash("md5"),f=e().createReadStream(a);f.on("data",a=>d.update(a)),f.on("end",()=>b(d.digest("hex"))),f.on("error",c)})}function q(a){try{return e().statSync(a).size}catch{return 0}}async function r(a,b,c,d={}){let f=Date.now(),h=(0,o.getProject)(a);if(!h)return{success:!1,duration:Date.now()-f,error:"Project not found"};let i=function(a,b){let c=new Date().toISOString().replace(/[:.]/g,"-");return`${a}-${b}-${c}.tar.gz`}(a,b),j=function(a){let b=function(){if(process.env.BACKUPS_BASE_DIR)return process.env.BACKUPS_BASE_DIR;let a=process.env.HOME||l().homedir()||"/home";return g().join(a,".supascale_backups")}(),c=g().join(b,a);return m(c),c}(a),k=g().join(j,i),n=(0,o.createBackup)({projectId:a,type:b,filename:i,path:k,size:0,encrypted:d.encrypt||!1,destination:c,status:"running",taskId:d.taskId});try{let a={};switch(b){case"database":a=await t(h,k);break;case"storage":a=await u(h,k);break;case"functions":a=await v(h,k);break;case"config":a=await w(h,k);break;case"full":a=await x(h,k);break;default:throw Error(`Unknown backup type: ${b}`)}let d=q(k),e=await p(k),g=k;"local"!==c&&(g=await y(k,c,i));let j=Date.now()-f;return(0,o.updateBackup)(n.id,{status:"completed",size:d,duration:j,checksum:e,path:g,metadata:a}),{success:!0,backupId:n.id,path:g,size:d,duration:j}}catch(c){let a=Date.now()-f,b=c instanceof Error?c.message:"Backup failed";(0,o.updateBackup)(n.id,{status:"failed",duration:a,errorMessage:b});try{e().existsSync(k)&&e().unlinkSync(k)}catch{}return{success:!1,backupId:n.id,duration:a,error:b}}}async function s(a,b,c){let d=await (0,n.eo)();if(d){let c=await (0,j.NK)(`${d?"podman":"docker"} ps -a --format "{{.Names}}|{{.ID}}"`);if(0!==c.exitCode||!c.stdout.trim())return null;let e=c.stdout.trim().split("\n").filter(Boolean),f=a.toLowerCase(),g=b.toLowerCase();for(let a of e){let[b,c]=a.split("|");if(!b||!c)continue;let d=b.toLowerCase();if(d.includes(f)&&(d.includes(`_${g}_`)||d.includes(`-${g}-`)||d.includes(`_${g}-`)||d.includes(`-${g}_`)||d.endsWith(`_${g}`)||d.endsWith(`-${g}`)))return c.trim()}return null}{let d=`docker compose -p ${(0,j.io)(a)} ps -q ${b}`;return(await (0,j.NK)(d,{cwd:c})).stdout.trim()||null}}async function t(a,b){let c=`${a.directory}/supabase/docker`,d=`/tmp/db_backup_${a.id}.dump`,f=await (0,n.eo)(),h=f?"podman-compose":"docker compose",i=`${h} -p ${(0,j.io)(a.id)} exec -T db pg_dump -U postgres -F c -b -v -f ${d}`,k=await (0,j.NK)(i,{cwd:c,timeout:6e5});if(0!==k.exitCode)throw Error(`pg_dump failed: ${k.stderr}`);let l=await s(a.id,"db",c);if(!l)throw Error("Could not find database container");let m=`${f?"podman":"docker"} cp ${(0,j.io)(l)}:${d} ${(0,j.io)(b.replace(".tar.gz",".dump"))}`,o=await (0,j.NK)(m);if(0!==o.exitCode)throw Error(`Failed to copy backup: ${o.stderr}`);let p=b.replace(".tar.gz",".dump"),r=`tar -czf ${(0,j.io)(b)} -C ${(0,j.io)(g().dirname(p))} ${(0,j.io)(g().basename(p))}`,t=await (0,j.NK)(r);if(0!==t.exitCode)throw Error(`Failed to compress backup: ${t.stderr}`);return e().unlinkSync(p),await (0,j.NK)(`${h} -p ${(0,j.io)(a.id)} exec -T db rm -f ${d}`,{cwd:c}),{databaseSize:q(b)}}async function u(a,b){let c=`${a.directory}/supabase/docker`,d=g().join(c,"volumes","storage");if(!e().existsSync(d)){let a=`tar -czf ${(0,j.io)(b)} --files-from /dev/null`;return await (0,j.NK)(a),{storageSize:0}}let f=`tar -czf ${(0,j.io)(b)} -C ${(0,j.io)(g().dirname(d))} ${(0,j.io)(g().basename(d))}`,h=await (0,j.NK)(f,{timeout:6e5});if(0!==h.exitCode)throw Error(`Failed to backup storage: ${h.stderr}`);return{storageSize:q(b)}}async function v(a,b){let c=g().join(a.directory,"supabase","functions");if(!e().existsSync(c)){let a=`tar -czf ${(0,j.io)(b)} --files-from /dev/null`;return await (0,j.NK)(a),{functionsCount:0}}let d=e().readdirSync(c,{withFileTypes:!0}).filter(a=>a.isDirectory()),f=`tar -czf ${(0,j.io)(b)} -C ${(0,j.io)(g().dirname(c))} ${(0,j.io)(g().basename(c))}`,h=await (0,j.NK)(f,{timeout:3e5});if(0!==h.exitCode)throw Error(`Failed to backup functions: ${h.stderr}`);return{functionsCount:d.length}}async function w(a,b){let c=`${a.directory}/supabase/docker`,d=[];for(let a of[".env","docker-compose.yml","docker-compose.override.yml"]){let b=g().join(c,a);e().existsSync(b)&&d.push(a)}if(0===d.length)throw Error("No configuration files found");let f=`tar -czf ${(0,j.io)(b)} -C ${(0,j.io)(c)} ${d.map(j.io).join(" ")}`,h=await (0,j.NK)(f);if(0!==h.exitCode)throw Error(`Failed to backup config: ${h.stderr}`);return{configFiles:d}}async function x(a,b){let c=`/tmp/supascale_backup_${a.id}_${Date.now()}`;m(c);let d=[],f={components:[]};try{try{let b=g().join(c,"database.tar.gz"),e=await t(a,b);d.push("database"),f.databaseSize=e.databaseSize}catch(a){console.error("Database backup failed:",a)}try{let b=g().join(c,"storage.tar.gz"),e=await u(a,b);d.push("storage"),f.storageSize=e.storageSize}catch(a){console.error("Storage backup failed:",a)}try{let b=g().join(c,"functions.tar.gz"),e=await v(a,b);d.push("functions"),f.functionsCount=e.functionsCount}catch(a){console.error("Functions backup failed:",a)}try{let b=g().join(c,"config.tar.gz"),e=await w(a,b);d.push("config"),f.configFiles=e.configFiles}catch(a){console.error("Config backup failed:",a)}if(0===d.length)throw Error("No components were successfully backed up");let h={projectId:a.id,projectName:a.name,createdAt:new Date().toISOString(),components:d,metadata:f};e().writeFileSync(g().join(c,"manifest.json"),JSON.stringify(h,null,2));let i=`tar -czf ${(0,j.io)(b)} -C ${(0,j.io)(c)} .`,k=await (0,j.NK)(i,{timeout:6e5});if(0!==k.exitCode)throw Error(`Failed to create full backup archive: ${k.stderr}`);return f.components=d,f}finally{try{e().rmSync(c,{recursive:!0,force:!0})}catch{}}}async function y(a,b,c){let d=(0,o.getCloudStorageProvider)(b);if(!d)throw Error(`Cloud storage provider not found: ${b}`);switch(d.type){case"s3":case"r2":case"minio":case"backblaze":if(!d.s3Config)throw Error("S3 configuration missing");return z(a,d,c);case"gcs":if(!d.gcsConfig)throw Error("GCS configuration missing");return A(a,d,c);case"azure":if(!d.azureConfig)throw Error("Azure configuration missing");return B(a,d,c);case"local":if(!d.localConfig)throw Error("Local storage configuration missing");return C(a,d,c);default:throw Error(`Unsupported storage type: ${d.type}`)}}async function z(a,b,d){let{S3Client:f,PutObjectCommand:g}=await Promise.resolve().then(c.t.bind(c,91043,23)),h=b.s3Config,i={region:h.region||"us-east-1",credentials:{accessKeyId:h.accessKeyId,secretAccessKey:h.secretAccessKey}};h.endpoint&&(i.endpoint=h.endpoint),(h.forcePathStyle||"minio"===b.type)&&(i.forcePathStyle=!0);let j=new f(i),k=h.pathPrefix?`${h.pathPrefix}/${d}`:d,l=e().readFileSync(a);return await j.send(new g({Bucket:h.bucket,Key:k,Body:l})),`s3://${h.bucket}/${k}`}async function A(a,b,d){try{let{Storage:e}=c(25527),f=b.gcsConfig,g=new e({projectId:f.projectId,keyFilename:f.keyFile}),h=f.pathPrefix?`${f.pathPrefix}/${d}`:d;return await g.bucket(f.bucket).upload(a,{destination:h}),`gs://${f.bucket}/${h}`}catch(a){if((a instanceof Error?a.message:"GCS upload failed").includes("Cannot find module"))throw Error("Google Cloud Storage SDK not installed. Install with: npm install @google-cloud/storage");throw a}}async function B(a,b,d){try{let e,{BlobServiceClient:f}=c(89226),g=b.azureConfig;if(g.connectionString)e=f.fromConnectionString(g.connectionString);else{let a=`DefaultEndpointsProtocol=https;AccountName=${g.accountName};AccountKey=${g.accountKey};EndpointSuffix=core.windows.net`;e=f.fromConnectionString(a)}let h=e.getContainerClient(g.containerName),i=g.pathPrefix?`${g.pathPrefix}/${d}`:d,j=h.getBlockBlobClient(i);return await j.uploadFile(a),`azure://${g.containerName}/${i}`}catch(a){if((a instanceof Error?a.message:"Azure upload failed").includes("Cannot find module"))throw Error("Azure Storage SDK not installed. Install with: npm install @azure/storage-blob");throw a}}async function C(a,b,c){let d=b.localConfig,f=d.basePath;if(!e().existsSync(f))if(d.createIfMissing)m(f);else throw Error(`Destination directory does not exist: ${f}`);let h=g().join(f,c);return e().copyFileSync(a,h),h}async function D(a,b,c){let d=(0,o.getCloudStorageProvider)(a);if(!d)throw Error(`Cloud storage provider not found: ${a}`);switch(d.type){case"s3":case"r2":case"minio":case"backblaze":if(!d.s3Config)throw Error("S3 configuration missing");await E(d,b,c);break;case"local":e().copyFileSync(b,c);break;default:throw Error(`Download not implemented for storage type: ${d.type}`)}}async function E(a,b,d){let{S3Client:f,GetObjectCommand:g}=await Promise.resolve().then(c.t.bind(c,91043,23)),h=a.s3Config,i={region:h.region||"us-east-1",credentials:{accessKeyId:h.accessKeyId,secretAccessKey:h.secretAccessKey}};h.endpoint&&(i.endpoint=h.endpoint),(h.forcePathStyle||"minio"===a.type)&&(i.forcePathStyle=!0);let j=new f(i),k=b;b.startsWith("s3://")&&(k=new URL(b.replace("s3://","https://")).pathname.slice(1));let l=(await j.send(new g({Bucket:h.bucket,Key:k}))).Body,m=e().createWriteStream(d);return new Promise((a,b)=>{l.pipe(m),m.on("finish",a),m.on("error",b)})}async function F(a,b){let c=Date.now(),d=[],f=(0,o.getBackup)(a);if(!f)return{success:!1,duration:Date.now()-c,error:"Backup not found"};let h=(0,o.getProject)(f.projectId);if(!h)return{success:!1,duration:Date.now()-c,error:"Project not found"};let i=b||("full"===f.type&&f.metadata?.components?f.metadata.components:[f.type]),k=(0,o.createRestoreJob)({projectId:h.id,backupId:f.id,status:"running",restoreTypes:i,startedAt:new Date().toISOString()});try{let a=f.path;if("local"===f.destination||e().existsSync(f.path)||(a=g().join("/tmp",`restore_${f.id}.tar.gz`),await D(f.destination,f.path,a)),"full"===f.type){let b=`/tmp/supascale_restore_${f.id}`;m(b);let c=`tar -xzf ${(0,j.io)(a)} -C ${(0,j.io)(b)}`,k=await (0,j.NK)(c);if(0!==k.exitCode)throw Error(`Failed to extract backup: ${k.stderr}`);for(let a of i)try{let c=g().join(b,`${a}.tar.gz`);e().existsSync(c)?await G(h,a,c):d.push(`Component ${a} not found in backup`)}catch(b){d.push(`Failed to restore ${a}: ${b instanceof Error?b.message:"Unknown error"}`)}e().rmSync(b,{recursive:!0,force:!0})}else await G(h,f.type,a);a!==f.path&&e().existsSync(a)&&e().unlinkSync(a);let b=Date.now()-c;return(0,o.updateRestoreJob)(k.id,{status:"completed",completedAt:new Date().toISOString(),duration:b,warnings:d.length>0?d:void 0}),{success:!0,duration:b,warnings:d.length>0?d:void 0}}catch(e){let a=Date.now()-c,b=e instanceof Error?e.message:"Restore failed";return(0,o.updateRestoreJob)(k.id,{status:"failed",completedAt:new Date().toISOString(),duration:a,errorMessage:b,warnings:d.length>0?d:void 0}),{success:!1,duration:a,error:b,warnings:d.length>0?d:void 0}}}async function G(a,b,c){switch(b){case"database":await H(a,c);break;case"storage":await I(a,c);break;case"functions":await J(a,c);break;case"config":await K(a,c);break;default:throw Error(`Unknown restore type: ${b}`)}}async function H(a,b){let c=`${a.directory}/supabase/docker`,d=`/tmp/db_restore_${a.id}`;m(d);let f=await (0,n.eo)(),h=f?"podman-compose":"docker compose",i=`tar -xzf ${(0,j.io)(b)} -C ${(0,j.io)(d)}`,k=await (0,j.NK)(i);if(0!==k.exitCode)throw Error(`Failed to extract database backup: ${k.stderr}`);let l=e().readdirSync(d).find(a=>a.endsWith(".dump"));if(!l)throw Error("Database dump file not found in archive");let o=g().join(d,l),p=`/tmp/restore_${a.id}.dump`,q=await s(a.id,"db",c);if(!q)throw Error("Database container not found");let r=`${f?"podman":"docker"} cp ${(0,j.io)(o)} ${(0,j.io)(q)}:${p}`,t=await (0,j.NK)(r);if(0!==t.exitCode)throw Error(`Failed to copy dump file: ${t.stderr}`);let u=`${h} -p ${(0,j.io)(a.id)} exec -T db pg_restore -U postgres -d postgres --clean --if-exists ${p}`,v=await (0,j.NK)(u,{cwd:c,timeout:6e5});if(0!==v.exitCode&&!v.stderr.includes("warning"))throw Error(`pg_restore failed: ${v.stderr}`);await (0,j.NK)(`${h} -p ${(0,j.io)(a.id)} exec -T db rm -f ${p}`,{cwd:c}),e().rmSync(d,{recursive:!0,force:!0})}async function I(a,b){let c=`${a.directory}/supabase/docker`,d=g().join(c,"volumes"),e=`tar -xzf ${(0,j.io)(b)} -C ${(0,j.io)(d)}`,f=await (0,j.NK)(e);if(0!==f.exitCode)throw Error(`Failed to restore storage: ${f.stderr}`)}async function J(a,b){let c=g().join(a.directory,"supabase"),d=`tar -xzf ${(0,j.io)(b)} -C ${(0,j.io)(c)}`,e=await (0,j.NK)(d);if(0!==e.exitCode)throw Error(`Failed to restore functions: ${e.stderr}`)}async function K(a,b){let c=`${a.directory}/supabase/docker`,d=`tar -xzf ${(0,j.io)(b)} -C ${(0,j.io)(c)}`,e=await (0,j.NK)(d);if(0!==e.exitCode)throw Error(`Failed to restore config: ${e.stderr}`)}async function L(a,b){let{backups:d}=await Promise.resolve().then(c.bind(c,35552)).then(b=>b.getAllBackups({projectId:a,status:"completed"}));if(d.length<=b)return 0;let f=d.sort((a,b)=>new Date(b.createdAt).getTime()-new Date(a.createdAt).getTime()).slice(b),g=0;for(let a of f)try{"local"===a.destination&&e().existsSync(a.path)&&e().unlinkSync(a.path),(0,o.deleteBackup)(a.id),g++}catch(b){console.error(`Failed to delete backup ${a.id}:`,b)}return g}async function M(a){let b=(0,o.getBackup)(a);if(!b)return!1;if("local"===b.destination&&e().existsSync(b.path))try{e().unlinkSync(b.path)}catch(a){console.error(`Failed to delete backup file: ${a}`)}return(0,o.deleteBackup)(a)}}};